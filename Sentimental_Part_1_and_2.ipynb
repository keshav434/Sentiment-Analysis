{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMehNyxo2WjFmvScvhoABS+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c6b99f55ae5b4cdd90252cbf7f562b57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e6878505b8c445889d65b76bb19c628",
              "IPY_MODEL_55c8107a9f3c4b019fdde0743c9eba55",
              "IPY_MODEL_226f752f706e49bbb3088b72b06ee556"
            ],
            "layout": "IPY_MODEL_0c12fe9bff394ef986af9051d288f5b9"
          }
        },
        "7e6878505b8c445889d65b76bb19c628": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2a0ae758b00498c905d2c2110ff7723",
            "placeholder": "​",
            "style": "IPY_MODEL_ef8f89f53ddb466da996113ffe82282e",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "55c8107a9f3c4b019fdde0743c9eba55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7a7a894d70e4c6b83d7692c4eb7cfea",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0879ed428eac4edb896d79f8f650bffd",
            "value": 231508
          }
        },
        "226f752f706e49bbb3088b72b06ee556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd554ca263bb4f3fa0bd723cbc1f3220",
            "placeholder": "​",
            "style": "IPY_MODEL_22b463423b824c9298341e505b4f7d05",
            "value": " 232k/232k [00:00&lt;00:00, 3.53MB/s]"
          }
        },
        "0c12fe9bff394ef986af9051d288f5b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2a0ae758b00498c905d2c2110ff7723": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef8f89f53ddb466da996113ffe82282e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7a7a894d70e4c6b83d7692c4eb7cfea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0879ed428eac4edb896d79f8f650bffd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd554ca263bb4f3fa0bd723cbc1f3220": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22b463423b824c9298341e505b4f7d05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "450747f7572743dd8c55ee54499b10c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f41cc36615c47a79738d3268243eed7",
              "IPY_MODEL_c5f87556f14649479244f7aea1eb4409",
              "IPY_MODEL_61d81543cf464399a2eb1d3fb58fb1cd"
            ],
            "layout": "IPY_MODEL_137b14650c3e40e79e529a5dd0304acd"
          }
        },
        "8f41cc36615c47a79738d3268243eed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_849ec69665b74b0cb7269e4513659f6a",
            "placeholder": "​",
            "style": "IPY_MODEL_2f511d4a2f924721b0f68d66d50a4ed0",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "c5f87556f14649479244f7aea1eb4409": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58cf8ec7a7e44de28df35067bdfb5144",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d25b40f9246044b1bb0ff4fbb0cc6095",
            "value": 28
          }
        },
        "61d81543cf464399a2eb1d3fb58fb1cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1d531d71c8d49c1bc476448624cd157",
            "placeholder": "​",
            "style": "IPY_MODEL_d09da03888554f0d803f344c57066af0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.35kB/s]"
          }
        },
        "137b14650c3e40e79e529a5dd0304acd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "849ec69665b74b0cb7269e4513659f6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f511d4a2f924721b0f68d66d50a4ed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58cf8ec7a7e44de28df35067bdfb5144": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d25b40f9246044b1bb0ff4fbb0cc6095": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1d531d71c8d49c1bc476448624cd157": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d09da03888554f0d803f344c57066af0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0fb6bc0b372b4f578d6f0b89a5aeeacd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a26810a2146d43ea89ffe4ec05825e8c",
              "IPY_MODEL_461418fcd3c04c0da5d6529873a391de",
              "IPY_MODEL_92332e41eff34f8aa4457a57dde76713"
            ],
            "layout": "IPY_MODEL_710a5a2c96e34926aa74bf6bc8c7f96e"
          }
        },
        "a26810a2146d43ea89ffe4ec05825e8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfed6ca5ca2d43beabf7ce57f72c751d",
            "placeholder": "​",
            "style": "IPY_MODEL_b8572f7524e84a7384fc2eb0a234be01",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "461418fcd3c04c0da5d6529873a391de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_caaaec863654479cb1427ae932b9df3c",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_760ccd505ccd400fba8fc3f1151521ee",
            "value": 483
          }
        },
        "92332e41eff34f8aa4457a57dde76713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e9f2c88e9224668a64e4d95dbd0ec98",
            "placeholder": "​",
            "style": "IPY_MODEL_54f1f38a942240e2a78a5bb9e55c155c",
            "value": " 483/483 [00:00&lt;00:00, 15.3kB/s]"
          }
        },
        "710a5a2c96e34926aa74bf6bc8c7f96e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfed6ca5ca2d43beabf7ce57f72c751d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8572f7524e84a7384fc2eb0a234be01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "caaaec863654479cb1427ae932b9df3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "760ccd505ccd400fba8fc3f1151521ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e9f2c88e9224668a64e4d95dbd0ec98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54f1f38a942240e2a78a5bb9e55c155c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d81b844fd8034217882269337e1b7d27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e69c63b0f1b945a99c526bbb15153459",
              "IPY_MODEL_2f700524d2234fc59a903550886058b5",
              "IPY_MODEL_97cd1bb666f94026b9be54424f1bce5f"
            ],
            "layout": "IPY_MODEL_32b5e58dda774d1f941d40eb53c0c1c5"
          }
        },
        "e69c63b0f1b945a99c526bbb15153459": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3431a84ec62494d98e4ef170347d001",
            "placeholder": "​",
            "style": "IPY_MODEL_a20ecab7eb894f11b04314bc0f09eeea",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "2f700524d2234fc59a903550886058b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d7d4574227844baaa64f3fd8590f76d",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f6b006665f404274a89980b96fd6bb9b",
            "value": 267954768
          }
        },
        "97cd1bb666f94026b9be54424f1bce5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bfe309dcded433588df774c87304db0",
            "placeholder": "​",
            "style": "IPY_MODEL_c3538eeed46340e5a4a1534a8768103b",
            "value": " 268M/268M [00:02&lt;00:00, 124MB/s]"
          }
        },
        "32b5e58dda774d1f941d40eb53c0c1c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3431a84ec62494d98e4ef170347d001": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a20ecab7eb894f11b04314bc0f09eeea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d7d4574227844baaa64f3fd8590f76d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6b006665f404274a89980b96fd6bb9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7bfe309dcded433588df774c87304db0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3538eeed46340e5a4a1534a8768103b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keshav434/Sentiment-Analysis/blob/main/Sentimental_Part_1_and_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c6b99f55ae5b4cdd90252cbf7f562b57",
            "7e6878505b8c445889d65b76bb19c628",
            "55c8107a9f3c4b019fdde0743c9eba55",
            "226f752f706e49bbb3088b72b06ee556",
            "0c12fe9bff394ef986af9051d288f5b9",
            "f2a0ae758b00498c905d2c2110ff7723",
            "ef8f89f53ddb466da996113ffe82282e",
            "d7a7a894d70e4c6b83d7692c4eb7cfea",
            "0879ed428eac4edb896d79f8f650bffd",
            "dd554ca263bb4f3fa0bd723cbc1f3220",
            "22b463423b824c9298341e505b4f7d05",
            "450747f7572743dd8c55ee54499b10c4",
            "8f41cc36615c47a79738d3268243eed7",
            "c5f87556f14649479244f7aea1eb4409",
            "61d81543cf464399a2eb1d3fb58fb1cd",
            "137b14650c3e40e79e529a5dd0304acd",
            "849ec69665b74b0cb7269e4513659f6a",
            "2f511d4a2f924721b0f68d66d50a4ed0",
            "58cf8ec7a7e44de28df35067bdfb5144",
            "d25b40f9246044b1bb0ff4fbb0cc6095",
            "c1d531d71c8d49c1bc476448624cd157",
            "d09da03888554f0d803f344c57066af0",
            "0fb6bc0b372b4f578d6f0b89a5aeeacd",
            "a26810a2146d43ea89ffe4ec05825e8c",
            "461418fcd3c04c0da5d6529873a391de",
            "92332e41eff34f8aa4457a57dde76713",
            "710a5a2c96e34926aa74bf6bc8c7f96e",
            "dfed6ca5ca2d43beabf7ce57f72c751d",
            "b8572f7524e84a7384fc2eb0a234be01",
            "caaaec863654479cb1427ae932b9df3c",
            "760ccd505ccd400fba8fc3f1151521ee",
            "7e9f2c88e9224668a64e4d95dbd0ec98",
            "54f1f38a942240e2a78a5bb9e55c155c",
            "d81b844fd8034217882269337e1b7d27",
            "e69c63b0f1b945a99c526bbb15153459",
            "2f700524d2234fc59a903550886058b5",
            "97cd1bb666f94026b9be54424f1bce5f",
            "32b5e58dda774d1f941d40eb53c0c1c5",
            "f3431a84ec62494d98e4ef170347d001",
            "a20ecab7eb894f11b04314bc0f09eeea",
            "5d7d4574227844baaa64f3fd8590f76d",
            "f6b006665f404274a89980b96fd6bb9b",
            "7bfe309dcded433588df774c87304db0",
            "c3538eeed46340e5a4a1534a8768103b"
          ]
        },
        "id": "rMT-pHakEbre",
        "outputId": "b298c5c2-b116-4c15-8241-85adfe6ec65d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "1.  Details after data loading\n",
            "Index(['Unnamed: 0', 'id', 'text', 'user_name', 'user_description',\n",
            "       'user_location', 'user_following', 'user_followers', 'tweets_by_user',\n",
            "       'user_created_at', 'tweet_created', 'retweets', 'likes', 'hashtags',\n",
            "       'media', 'search_term', 'emojis', 'sentiments_list',\n",
            "       'revised_sentiment', 'distillbert_valence'],\n",
            "      dtype='object')\n",
            "   Unnamed: 0                   id  \\\n",
            "0      253291  1359216214875262980   \n",
            "1      253283  1359691122985947137   \n",
            "2      253280  1359697180987183105   \n",
            "3      253268  1359718063994667009   \n",
            "4      253260  1359734007731269632   \n",
            "\n",
            "                                                text        user_name  \\\n",
            "0  three palm oil firms were responsible for a qu...  hoteldealphuket   \n",
            "1  despicable #brazil govt using #pandemic as cov...       PhelimKine   \n",
            "2  🌳🍂🌳impacto humano no #desmatamento / \\nhuman i...        isis_0726   \n",
            "3  deforestation will be the end of the human rac...   AmanzWillieONE   \n",
            "4  @_wrong_guy_ @zerohedge no other codes nowdays...     GordonGecko3   \n",
            "\n",
            "                                    user_description user_location  \\\n",
            "0  Phuket Hotel Deals offers Phuket property for ...        Phuket   \n",
            "1  Senior Director Asia @StandMighty @TeamWaxman;...  Asia Pacific   \n",
            "2  ☮⏳🌍🌎🌏O erro da ética tem sido a crença de que ...           NaN   \n",
            "3  Sincerity, Awards winner, Crusading Climate an...       Africa.   \n",
            "4  Gold/Silver/Oil/Uranium-Bug\\nhttps://t.co/AZNz...     Worldwide   \n",
            "\n",
            "   user_following  user_followers  tweets_by_user      user_created_at  \\\n",
            "0              53             288           63131  2013-10-23 01:50:59   \n",
            "1            1326           19024           53843  2011-09-16 07:06:02   \n",
            "2             115              31            3724  2019-10-27 21:15:12   \n",
            "3             889             627            3357  2018-11-11 03:14:22   \n",
            "4             896             242            9518  2011-08-13 20:41:04   \n",
            "\n",
            "         tweet_created  retweets  likes  \\\n",
            "0  2021-02-09 19:02:53         0      0   \n",
            "1  2021-02-11 02:30:00         0      2   \n",
            "2  2021-02-11 02:54:04         0      0   \n",
            "3  2021-02-11 04:17:03         1      2   \n",
            "4  2021-02-11 05:20:24         0      1   \n",
            "\n",
            "                                            hashtags  \\\n",
            "0  [{'text': 'animal_rehabilitation', 'indices': ...   \n",
            "1  [{'text': 'Brazil', 'indices': [12, 19]}, {'te...   \n",
            "2  [{'text': 'desmatamento', 'indices': [21, 34]}...   \n",
            "3                                                 []   \n",
            "4                                                 []   \n",
            "\n",
            "                                               media  \\\n",
            "0     http://pbs.twimg.com/media/Etzn8WuXIAAZ2ju.jpg   \n",
            "1     http://pbs.twimg.com/media/Et4nD6zXMAMTg2V.jpg   \n",
            "2     http://pbs.twimg.com/media/Et6dYS4WQAAoNul.jpg   \n",
            "3     http://pbs.twimg.com/media/Et6wX0HUYAUrGlg.jpg   \n",
            "4  http://pbs.twimg.com/tweet_video_thumb/Et6-3nx...   \n",
            "\n",
            "                      search_term           emojis sentiments_list  \\\n",
            "0  deforestation -filter:retweets              NaN             NaN   \n",
            "1  deforestation -filter:retweets              NaN             NaN   \n",
            "2  deforestation -filter:retweets  {'🌳', '❌', '🍂'}     {'neutral'}   \n",
            "3  deforestation -filter:retweets              NaN             NaN   \n",
            "4  deforestation -filter:retweets            {'😉'}    {'positive'}   \n",
            "\n",
            "  revised_sentiment  distillbert_valence  \n",
            "0          negative            -0.992038  \n",
            "1          negative            -0.997723  \n",
            "2          negative            -0.973575  \n",
            "3          negative            -0.963673  \n",
            "4          negative            -0.995930  \n",
            "     Unnamed: 0                   id  \\\n",
            "934      200166  1394397654268907522   \n",
            "935      200160  1394404608940789762   \n",
            "936      200159  1394404998235054082   \n",
            "937      200155  1394412410837028866   \n",
            "938      200154  1394412479434817537   \n",
            "\n",
            "                                                  text        user_name  \\\n",
            "934  @greenworld_uk @thegreenparty sir david attenb...        griffjane   \n",
            "935  the silvery gibbon is of genus 'hylobates' whi...    PalmOilDetect   \n",
            "936  how to stop deforestation 🌲💪 https://tco/a9r2z...  SADeforestation   \n",
            "937  do you accept the challenge before entering: w...        SgkPlanet   \n",
            "938  the more lighter we take the subject of defore...     EcoSoulHome1   \n",
            "\n",
            "                                      user_description  \\\n",
            "934  Retired Head of English, but still involved wi...   \n",
            "935  An exciting new platform & consumer website fo...   \n",
            "936  We are two middle school students trying to sp...   \n",
            "937  Enter SGK-PLANET and you will be surprised wit...   \n",
            "938                            https://t.co/6PX8ltn8G5   \n",
            "\n",
            "               user_location  user_following  user_followers  tweets_by_user  \\\n",
            "934                 Cornwall            1100             894           12161   \n",
            "935  Wellington, New Zealand            1854            1932            5489   \n",
            "936                 Reno, NV               8               0               7   \n",
            "937                      NaN             221             221            7752   \n",
            "938                      NaN               1               0              48   \n",
            "\n",
            "         user_created_at        tweet_created  retweets  likes  \\\n",
            "934  2012-02-29 17:28:38  2021-05-17 21:01:22         0      1   \n",
            "935  2021-01-19 07:50:52  2021-05-17 21:29:00         4      5   \n",
            "936  2021-05-17 21:18:03  2021-05-17 21:30:33         0      0   \n",
            "937  2018-04-22 21:37:44  2021-05-17 22:00:00         3      0   \n",
            "938  2021-01-27 01:27:12  2021-05-17 22:00:16         0      0   \n",
            "\n",
            "                                              hashtags  \\\n",
            "934                                                 []   \n",
            "935  [{'text': 'palmoil', 'indices': [207, 215]}, {...   \n",
            "936                                                 []   \n",
            "937  [{'text': 'Amazon', 'indices': [57, 64]}, {'te...   \n",
            "938  [{'text': 'PalmLeafPlates', 'indices': [264, 2...   \n",
            "\n",
            "                                                 media  \\\n",
            "934     http://pbs.twimg.com/media/E1nlRomXoAAp6UL.jpg   \n",
            "935  http://pbs.twimg.com/ext_tw_video_thumb/138594...   \n",
            "936     http://pbs.twimg.com/media/E1nr8yJUcAEmDvA.png   \n",
            "937     http://pbs.twimg.com/media/E1mFkUKWYAIsnYn.jpg   \n",
            "938     http://pbs.twimg.com/media/E1nywtaUYAAsr9N.jpg   \n",
            "\n",
            "                        search_term      emojis          sentiments_list  \\\n",
            "934  deforestation -filter:retweets         NaN                      NaN   \n",
            "935  deforestation -filter:retweets         NaN                      NaN   \n",
            "936  deforestation -filter:retweets  {'💪', '🌲'}  {'positive', 'neutral'}   \n",
            "937  deforestation -filter:retweets         NaN                      NaN   \n",
            "938  deforestation -filter:retweets       {'😍'}             {'positive'}   \n",
            "\n",
            "    revised_sentiment  distillbert_valence  \n",
            "934          negative             0.987127  \n",
            "935          negative             0.991482  \n",
            "936          negative            -0.982717  \n",
            "937          negative            -0.987794  \n",
            "938          negative            -0.997201  \n",
            "2. Clean Text -----------\n",
            "0      three palm oil firms were responsible for a qu...\n",
            "1      despicable govt using as cover to dilute envir...\n",
            "2                      impacto humano no human impact on\n",
            "3      deforestation will be the end of the human rac...\n",
            "4      no other codes nowdays seriously you cant buil...\n",
            "                             ...                        \n",
            "934    sir david attenborough says we can protect wil...\n",
            "935    the silvery gibbon is of genus hylobates which...\n",
            "936                            how to stop deforestation\n",
            "937    do you accept the challenge before entering wh...\n",
            "938    the more lighter we take the subject of defore...\n",
            "Name: clean_text, Length: 939, dtype: object\n",
            "Index(['Unnamed: 0', 'id', 'text', 'user_name', 'user_description',\n",
            "       'user_location', 'user_following', 'user_followers', 'tweets_by_user',\n",
            "       'user_created_at', 'tweet_created', 'retweets', 'likes', 'hashtags',\n",
            "       'media', 'search_term', 'emojis', 'sentiments_list',\n",
            "       'revised_sentiment', 'distillbert_valence', 'clean_text'],\n",
            "      dtype='object')\n",
            "   Unnamed: 0                   id  \\\n",
            "0      253291  1359216214875262980   \n",
            "1      253283  1359691122985947137   \n",
            "2      253280  1359697180987183105   \n",
            "3      253268  1359718063994667009   \n",
            "4      253260  1359734007731269632   \n",
            "\n",
            "                                                text        user_name  \\\n",
            "0  three palm oil firms were responsible for a qu...  hoteldealphuket   \n",
            "1  despicable #brazil govt using #pandemic as cov...       PhelimKine   \n",
            "2  🌳🍂🌳impacto humano no #desmatamento / \\nhuman i...        isis_0726   \n",
            "3  deforestation will be the end of the human rac...   AmanzWillieONE   \n",
            "4  @_wrong_guy_ @zerohedge no other codes nowdays...     GordonGecko3   \n",
            "\n",
            "                                    user_description user_location  \\\n",
            "0  Phuket Hotel Deals offers Phuket property for ...        Phuket   \n",
            "1  Senior Director Asia @StandMighty @TeamWaxman;...  Asia Pacific   \n",
            "2  ☮⏳🌍🌎🌏O erro da ética tem sido a crença de que ...           NaN   \n",
            "3  Sincerity, Awards winner, Crusading Climate an...       Africa.   \n",
            "4  Gold/Silver/Oil/Uranium-Bug\\nhttps://t.co/AZNz...     Worldwide   \n",
            "\n",
            "   user_following  user_followers  tweets_by_user      user_created_at  ...  \\\n",
            "0              53             288           63131  2013-10-23 01:50:59  ...   \n",
            "1            1326           19024           53843  2011-09-16 07:06:02  ...   \n",
            "2             115              31            3724  2019-10-27 21:15:12  ...   \n",
            "3             889             627            3357  2018-11-11 03:14:22  ...   \n",
            "4             896             242            9518  2011-08-13 20:41:04  ...   \n",
            "\n",
            "  retweets  likes                                           hashtags  \\\n",
            "0        0      0  [{'text': 'animal_rehabilitation', 'indices': ...   \n",
            "1        0      2  [{'text': 'Brazil', 'indices': [12, 19]}, {'te...   \n",
            "2        0      0  [{'text': 'desmatamento', 'indices': [21, 34]}...   \n",
            "3        1      2                                                 []   \n",
            "4        0      1                                                 []   \n",
            "\n",
            "                                               media  \\\n",
            "0     http://pbs.twimg.com/media/Etzn8WuXIAAZ2ju.jpg   \n",
            "1     http://pbs.twimg.com/media/Et4nD6zXMAMTg2V.jpg   \n",
            "2     http://pbs.twimg.com/media/Et6dYS4WQAAoNul.jpg   \n",
            "3     http://pbs.twimg.com/media/Et6wX0HUYAUrGlg.jpg   \n",
            "4  http://pbs.twimg.com/tweet_video_thumb/Et6-3nx...   \n",
            "\n",
            "                      search_term           emojis sentiments_list  \\\n",
            "0  deforestation -filter:retweets              NaN             NaN   \n",
            "1  deforestation -filter:retweets              NaN             NaN   \n",
            "2  deforestation -filter:retweets  {'🌳', '❌', '🍂'}     {'neutral'}   \n",
            "3  deforestation -filter:retweets              NaN             NaN   \n",
            "4  deforestation -filter:retweets            {'😉'}    {'positive'}   \n",
            "\n",
            "  revised_sentiment distillbert_valence  \\\n",
            "0          negative           -0.992038   \n",
            "1          negative           -0.997723   \n",
            "2          negative           -0.973575   \n",
            "3          negative           -0.963673   \n",
            "4          negative           -0.995930   \n",
            "\n",
            "                                          clean_text  \n",
            "0  three palm oil firms were responsible for a qu...  \n",
            "1  despicable govt using as cover to dilute envir...  \n",
            "2                  impacto humano no human impact on  \n",
            "3  deforestation will be the end of the human rac...  \n",
            "4  no other codes nowdays seriously you cant buil...  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "X,y 0      three palm oil firms were responsible for a qu...\n",
            "1      despicable govt using as cover to dilute envir...\n",
            "2                      impacto humano no human impact on\n",
            "3      deforestation will be the end of the human rac...\n",
            "4      no other codes nowdays seriously you cant buil...\n",
            "                             ...                        \n",
            "934    sir david attenborough says we can protect wil...\n",
            "935    the silvery gibbon is of genus hylobates which...\n",
            "936                            how to stop deforestation\n",
            "937    do you accept the challenge before entering wh...\n",
            "938    the more lighter we take the subject of defore...\n",
            "Name: clean_text, Length: 939, dtype: object 0                          NaN\n",
            "1                          NaN\n",
            "2                  {'neutral'}\n",
            "3                          NaN\n",
            "4                 {'positive'}\n",
            "                ...           \n",
            "934                        NaN\n",
            "935                        NaN\n",
            "936    {'positive', 'neutral'}\n",
            "937                        NaN\n",
            "938               {'positive'}\n",
            "Name: sentiments_list, Length: 939, dtype: object\n",
            "len(y)-> 939\n",
            "impacto humano no human impact ...  0.5\n",
            "no other codes nowdays serious ...  1.0\n",
            "this could help for starters c ...  0.5\n",
            "doesn t green looks awesome ra ...  1.0\n",
            "madelaine y alfelor gazman may ...  0.5\n",
            "meet giselle is doing her phd  ...  1.0\n",
            "eu public opposes trade deal a ...  0.5\n",
            "fran ois lombard of underlined ...  0.5\n",
            "and partnered with communities ...  0.5\n",
            "and partnered with communities ...  0.5\n",
            "well said anna yes absolutely  ...  0.5\n",
            "deforestation will be the end  ...  0.25\n",
            "deforestation is changing our  ...  0.5\n",
            "to combat deforestation and he ...  0.5\n",
            "happy pangolins can be found i ...  0.75\n",
            "meateaters amp animal ag they  ...  1.0\n",
            "happy pangolins are facing ser ...  0.5\n",
            "is on world side so se support ...  0.5\n",
            "i can t believe we are still a ...  0.0\n",
            "envirolent day you are the sal ...  0.5\n",
            "what this all stupid things go ...  0.0\n",
            "that our beekeepers place beeh ...  0.5\n",
            "what an authentic vignette it  ...  0.5\n",
            "not learning the age old lesso ...  0.0\n",
            "soz but the two are incompatib ...  0.25\n",
            "in hundreds of years old pine  ...  0.5\n",
            "sorry sir no deforestation in  ...  1.0\n",
            "a kind reminder that deforesta ...  0.25\n",
            "to combat deforestation and he ...  0.5\n",
            "of people living in rural area ...  0.5\n",
            "program how can we actively re ...  0.5\n",
            "in artist klaus littmann turne ...  0.5\n",
            "i fail to understand our envir ...  0.5\n",
            "how to stop runaway deforestat ...  0.75\n",
            "how to stop runaway deforestat ...  0.75\n",
            "tropical are under increasing  ...  0.5\n",
            "according to tobacco is deadly ...  0.5\n",
            "this robot could help plant tr ...  0.5\n",
            "defines a restrictive policy t ...  0.75\n",
            "what is the evidence on crimin ...  0.5\n",
            "deforestation green recovery f ...  0.5\n",
            "an ambitious amp successful pl ...  0.5\n",
            "baka pygmies east cameroon the ...  0.5\n",
            "the black jaguar foundation pl ...  1.0\n",
            "the fta conflicts with ambitio ...  0.5\n",
            "forests cover of the earth s l ...  0.5\n",
            "this photo documents the exten ...  0.5\n",
            "bobble vytas and andreana swop ...  0.5\n",
            "your soy milk ain t the proble ...  0.5\n",
            "from to the to the us countrie ...  0.5\n",
            "deforestation ...  1.0\n",
            "urgent this is our call this i ...  0.5\n",
            "experts have made a sad observ ...  0.0\n",
            "did you know read more about s ...  0.5\n",
            "earthsight s grand theft chaco ...  0.5\n",
            "a bird view let it be green am ...  0.75\n",
            "treedom community hear us out  ...  0.5\n",
            "kudos to norway ...  0.75\n",
            "tackling is a complex issue an ...  0.75\n",
            "forests play a central role in ...  0.75\n",
            "deforestation of dahaiyagala s ...  0.5\n",
            "to celebrate our latest blog d ...  0.5\n",
            "human activity is driving almo ...  0.5\n",
            "great work from struan in s cr ...  0.5\n",
            "we can prevent by empowering a ...  0.75\n",
            "livestock livestock everywhere ...  0.0\n",
            "eco friendly black owned that  ...  0.5\n",
            "is on world side so se support ...  0.5\n",
            "calling on to list as a non pr ...  0.5\n",
            "meet the graduate students wor ...  0.75\n",
            "incoming call we are calling o ...  0.25\n",
            "the production of food has a m ...  0.5\n",
            "eu based banks are bankrolling ...  0.5\n",
            "class have been looking at def ...  0.5\n",
            "in our globalized distant conn ...  0.5\n",
            "but is cutting grown in appeal ...  0.5\n",
            "on march the will vote on a fr ...  0.5\n",
            "deforestation is one of the gr ...  0.5\n",
            "if the wants to lead the globa ...  0.5\n",
            "did you know before there were ...  0.75\n",
            "according to only basic produc ...  0.5\n",
            "this week s inspirational wome ...  0.5\n",
            "bnp paribas defines restrictiv ...  0.5\n",
            "with has launched a new partne ...  0.5\n",
            "threatens our prosperity and w ...  0.5\n",
            "is thriving in latin america o ...  0.75\n",
            "this sign reads it is prohibit ...  0.5\n",
            "forests play a key role in sus ...  0.75\n",
            "among the climate change fund  ...  0.5\n",
            "flegt compliance in ghana logg ...  0.5\n",
            "the brazilian cerrado is one o ...  0.5\n",
            "deforestation comparison below ...  0.5\n",
            "all our products are palm oil  ...  0.75\n",
            "key examples of human induced  ...  0.5\n",
            "it s today forests provide a c ...  0.5\n",
            "want to find out how deforesta ...  0.5\n",
            "soy used as animal feed for in ...  0.5\n",
            "today is let s remember the cr ...  0.5\n",
            "i know i should be prepping ta ...  0.5\n",
            "last year ferrero made signifi ...  0.5\n",
            "commodity driven deforestation ...  0.5\n",
            "civil society organizations ha ...  0.5\n",
            "p have been learning at home a ...  0.5\n",
            "and in forests are disappearin ...  0.5\n",
            "it s celebrating forests and t ...  0.5\n",
            "deforestation of the amazon an ...  0.5\n",
            "happy in it s celebrating how  ...  0.75\n",
            "unsustainable palm oil product ...  0.25\n",
            "you might think avoiding is th ...  1.0\n",
            "our forests are home to some c ...  0.5\n",
            "this seven year old girl is fi ...  0.5\n",
            "yes public the cult of meat ea ...  0.5\n",
            "in order to protect ourselves  ...  0.5\n",
            "did you know leopard spots are ...  1.0\n",
            "forests have a central role in ...  0.75\n",
            "wildlife is threatened by defo ...  0.5\n",
            "cameroon s forests are home to ...  1.0\n",
            "amazon indigenous groups sue c ...  0.5\n",
            "today brings to our attention  ...  0.75\n",
            "give back to nature is very ha ...  0.75\n",
            "happy forests play a central r ...  1.0\n",
            "is on world side so se support ...  0.5\n",
            "not only is organic it s also  ...  0.5\n",
            "when you notice it a movie abo ...  1.0\n",
            "year are learning about how th ...  0.5\n",
            "urban growth co solihull forge ...  0.5\n",
            "ag indicts for reckless drivin ...  0.25\n",
            "transparency is crucial in our ...  0.75\n",
            "that pallite products are made ...  0.5\n",
            "day of solutions live updates  ...  0.75\n",
            "the us relies heavily on impor ...  0.5\n",
            "unequal hours unraveling appro ...  0.5\n",
            "thank you for the article but  ...  0.5\n",
            "direct human causes of defores ...  0.5\n",
            "french supermarket chain sued  ...  0.5\n",
            "year have been celebrating by  ...  0.5\n",
            "climate change is cause by def ...  0.5\n",
            "could your shopping be contrib ...  0.25\n",
            "we ve reached the final day of ...  0.75\n",
            "event environmental justice in ...  0.5\n",
            "un suspends climate work with  ...  0.0\n",
            "gwg star of the week lesein mu ...  1.0\n",
            "we have a pretty extensive lis ...  1.0\n",
            "how is the covid pandemic conn ...  0.5\n",
            "governments of amp are priorit ...  0.5\n",
            "y all fuckin with deforestatio ...  0.5\n",
            "in an interview published on s ...  0.5\n",
            "week i tried to make a nice ye ...  0.5\n",
            "if a muslim who plants a tree  ...  0.0\n",
            "indigenous territories are vit ...  0.75\n",
            "indonesia and malaysia are now ...  0.5\n",
            "fertilizers play a key role in ...  0.5\n",
            "this report analyzes private i ...  0.5\n",
            "forest area skmc hospital camp ...  0.5\n",
            "another day another habitat de ...  1.0\n",
            "the forest has always been ass ...  0.5\n",
            "at least once a let s avoid ov ...  0.5\n",
            "award winning filmmaker and s  ...  1.0\n",
            "with the new feature called ti ...  0.5\n",
            "chile s varied landscapes are  ...  0.5\n",
            "nobdy understands by vry meani ...  0.0\n",
            "amp freshwater pollution have  ...  0.5\n",
            "is on world side so se support ...  0.5\n",
            "in as president of the duke of ...  0.5\n",
            "the transboundary region betwe ...  0.5\n",
            "no incidence of fire combined  ...  0.5\n",
            "our buy one get one tree promo ...  0.5\n",
            "soon do you want to learn abou ...  0.5\n",
            "boycott genshin mihoyo is not  ...  0.25\n",
            "chile s varied landscapes are  ...  0.5\n",
            "s menabe antimena protected ar ...  0.75\n",
            "global tree loss can t hide fr ...  0.5\n",
            "keep our planet green stop def ...  0.5\n",
            "calling all welsh schools size ...  0.5\n",
            "take majority land back livest ...  0.5\n",
            "happy birthday from montana de ...  0.75\n",
            "thank you alumni for creating  ...  0.5\n",
            "climate change is an risk that ...  0.5\n",
            "stanford study cause of the wa ...  0.5\n",
            "deforestation and corruption a ...  0.25\n",
            "the series o grito do brasil s ...  0.5\n",
            "plant trees and protect them t ...  0.5\n",
            "plant trees and protect them t ...  0.5\n",
            "plant trees and protect them t ...  0.5\n",
            "animation by will make you go  ...  0.5\n",
            "we have just signed up to to o ...  0.5\n",
            "investment giant holds million ...  0.5\n",
            "deforestation is threatening f ...  0.5\n",
            "voting with patriotism is fund ...  0.5\n",
            "don t forget to tune in instag ...  1.0\n",
            "when animals are safe from def ...  1.0\n",
            "co converters are already out  ...  0.75\n",
            "how to stop deforestation ...  0.75\n",
            "the more lighter we take the s ...  1.0\n",
            "   \n",
            "5672\n",
            "1768\n",
            "['impacto', 'humano', 'no', 'human', 'impact', 'on', 'no', 'other', 'codes', 'nowdays', 'seriously', 'you', 'cant', 'build', 'windmill', 'without', 'tons', 'of', 'concrete', 'tons']\n",
            "***************vocab_to_int.keys, vocab_to_int.values ********\n",
            "['resilient', 'medicines', 'threat', 'helpdesk', 'documenting'] [0, 1, 2, 3, 4]\n",
            "***************int_to_vocab.keys, int_to_vocab.values ********\n",
            "[0, 1, 2, 3, 4] ['resilient', 'medicines', 'threat', 'helpdesk', 'documenting']\n",
            "Vocabulary of our dataset: 1768\n",
            "Data stats - \n",
            "45 132 17\n",
            "Feature Shapes:\n",
            "\tTrain set: \t\t(182,) \n",
            "\tTest set: \t\t(12,)\n",
            "Totals:\n",
            "\tWords in our Dataset: 1768\n",
            "\n",
            "[[20, 418, 1658, 1218, 950, 1578, 25, 1305, 175, 1305, 686, 274, 557, 535, 1305, 452, 1581, 127, 646, 418, 152, 265, 610, 1014, 97, 1663, 1585, 1039, 1661, 535, 1358, 1628, 1305, 303, 1305, 351, 332, 1189, 1209, 1303, 722, 1661, 535, 574, 862, 169], [1733, 375, 1595, 610, 101, 708, 222, 1505], [1285, 1305, 175, 734, 610, 570, 822, 254, 48, 451, 518, 874, 1474, 931, 300, 535, 576, 1305, 473, 661, 121, 1174, 216, 1585, 1222, 412], [1285, 1305, 175, 734, 610, 570, 822, 254, 48, 451, 518, 874, 1474, 931, 300, 535, 576, 1305, 473, 661, 121, 1174, 216, 1585, 1222, 412], [714, 1209, 270, 1749, 1305, 897, 101, 152, 429, 1474, 152, 879, 953], [152, 1621, 1229, 269, 996, 963, 1188, 101, 152, 415, 1465, 282, 1424, 1711, 152, 1462, 604, 1199, 1474, 79, 610, 101, 152, 706, 111, 798, 1421, 1305, 342, 152, 131, 980, 1188, 242, 1322, 327, 802, 152, 1337, 381], [610], [1209, 1675, 1707, 1021, 799, 1256, 1730, 418, 114, 26, 485, 96, 683, 759, 101, 152, 1010, 604, 610, 518, 893, 1585, 152, 833, 604, 252, 215, 1552, 1663, 799, 378, 214], [1370, 1305, 22], [1170, 1585, 1209, 1502, 1072, 1474, 559, 152, 1305, 473, 198, 951, 1585, 789, 1209, 219, 248, 1351, 850, 804, 606, 1378, 1711, 1594, 1073, 342, 604, 1176, 157, 378, 451, 770, 604, 684, 700, 449], [653, 422, 1209, 839, 51, 101, 1366, 507, 1304, 683, 1391, 1110, 518, 1023, 876, 1121, 633, 586, 742, 9, 436, 1192, 204, 470, 802, 1594, 418, 1687], [421, 298, 686, 518, 676, 418, 390, 297, 1305, 12, 348, 555, 503, 200, 127, 806, 418, 1390, 1041, 29, 1752, 503, 1397, 432, 306, 1299, 1545, 50, 1480, 845, 78, 1390, 336, 1220, 327, 1188], [373, 152, 362, 163, 1267, 101, 110, 254, 1474, 1102, 1514, 501, 779, 548, 1305, 1363, 825, 563, 859, 1262, 511, 1305, 782, 24, 586, 610, 418, 473, 521], [67, 798, 249, 1143, 1698, 1313, 40, 632, 604, 630, 653, 101, 152, 1383, 1734, 276, 799, 27, 423, 1305, 1519, 616, 632, 1066, 1305, 610, 683, 1585, 551, 421, 887, 309, 1434, 1177, 449, 518, 275, 152, 1289, 493], [1585, 959, 101, 961, 257, 1322, 565, 1133, 1716, 1397, 967, 101, 152, 706, 673, 139, 117, 604, 587, 72, 231, 1577, 610, 152, 51, 604, 1163], [653, 422, 1209, 816, 51, 101, 1366, 507, 1304, 683, 152, 1391, 1110, 518, 1023, 916, 1719, 1121, 742, 9, 436, 1711, 204, 470, 802, 1594, 418, 1687], [984, 1322, 1480, 916, 336, 1220, 1474, 10, 906, 1305, 585, 1032, 586, 610, 101, 152, 429, 1035, 421, 1456, 397, 1711, 1247, 305, 1164, 1664, 1382, 39, 549, 1474, 1642, 1613, 1444], [696, 101, 799, 378, 1134, 1285, 1322, 1407, 378, 653, 909, 297, 1474, 1337, 54, 1021, 378, 930, 1209, 570, 822, 1285, 298, 782, 610, 1474, 925, 1555, 418, 1594, 504], [798, 6, 1403, 1320, 1585, 152, 479, 1734, 152, 552, 1029, 1403, 54, 1019, 1220, 266, 29, 449, 1412, 54, 1154, 1536, 237, 152, 282, 747, 1072, 1198, 610, 906, 1585, 1209, 348, 847], [67, 798, 249, 1500, 1244, 916, 983, 190, 1359, 950, 7, 1209, 1626, 276, 798, 247, 216, 460, 378, 1407, 1014, 743, 1585, 638, 1285, 687, 818, 418, 610, 916, 852, 473, 1437, 418, 152, 507, 604, 152, 1594, 473, 504], [653, 535, 1209, 839, 51, 101, 1366, 297, 378, 507, 35, 1366, 1354, 991, 667, 477, 777, 152, 916, 1182, 802, 682, 421, 298, 818, 683, 1711, 901, 610, 1598], [64, 378, 653, 916, 487, 1305, 563, 1543, 1086, 604, 1437, 1734, 705, 610, 546, 202, 1117, 439, 1305, 1200, 118, 1582, 135, 532, 822, 1322, 1728, 825, 333, 702, 1209, 122, 1305, 317, 342, 1322, 1286, 677], [1650, 209, 1305, 1322, 1584, 1578, 1285, 174, 916, 282, 747, 687, 818, 1474, 610, 916, 211, 1333, 421, 887, 1076, 152, 741, 1305, 1322, 197, 54, 421, 986, 1029, 452, 1319, 1711, 1209], [702, 1724, 1305, 1663, 1585, 945, 696, 1305, 1498, 993, 856, 1711, 660, 1003, 1062, 950, 535, 1071, 1449, 1188, 101, 1391, 82, 518, 610, 1474, 1609, 1305, 1405, 1070, 802, 1740, 958, 1685], [696, 653, 422, 1209, 839, 51, 101, 1366, 507, 152, 1304, 683, 1391, 1110, 518, 1023, 916, 1719, 1121, 742, 9, 436, 170, 1594, 507, 418, 1687], [1549, 798, 1503, 799, 1209, 119, 638, 610], [919, 1585, 1538, 101, 1322, 897, 1524, 610, 1474, 473, 521, 424, 914, 1267, 1583, 1443, 820, 1305, 1534, 1397, 1238, 1186, 152, 1513, 604, 473, 198, 951], [743, 604, 1695, 580, 508, 1326, 1012, 956, 466, 1474, 152, 163, 604, 583, 838, 181, 182, 101, 1171, 1271, 825, 1152, 1711, 993, 866, 712, 604, 610, 101, 1017, 644, 993, 1125, 580, 825, 1012, 378, 443], [421, 725, 1135, 152, 1002, 743, 604, 1474, 421, 450, 760, 1396, 1585, 1698, 378, 216, 1474, 449, 825, 1322, 912, 1179, 906, 526, 443, 802, 1474, 1333, 493], [783, 1596, 604, 152, 1204, 1518, 272, 1585, 1209, 460, 1566, 52, 1316, 181, 177, 1514, 1203, 1586, 1474, 94, 785, 278, 638, 320, 610, 1474, 687, 818, 1527, 1541, 191, 775, 802, 1586, 1711, 1405, 1188], [421, 535, 1209, 975, 749, 1275, 604, 1335, 1549, 799, 1610, 1305, 184, 1322, 1334, 387, 485, 1764, 798, 640, 1431, 58, 1553, 1322, 1334, 387, 916, 1169, 1643, 623, 195, 101, 1026, 509, 505, 1474, 1212, 586, 224, 544, 610, 1585, 563, 1072, 240, 906], [370, 1034, 916, 832, 101, 961, 257, 1474, 152, 1683, 950, 1410, 604, 984, 540, 101, 1034, 101, 152, 723, 429, 848, 1475, 705, 608, 705, 1019, 519, 1391], [286, 743, 286, 1384, 1159, 518], [738, 756, 753, 1474, 378, 243, 1510, 763, 378, 424, 80, 494, 349, 926, 1063, 1111, 1665, 1507, 4, 152, 1517, 82, 1448, 1131, 604, 610, 151, 1510, 763, 1474, 389], [378, 1239, 1050, 519, 205, 1585, 101, 1290, 1148, 460, 632, 604, 473, 1313, 1159, 683, 378, 1150, 277, 111, 216, 396, 546, 799, 1133, 1256, 1408, 101, 1131, 564, 1585, 1267, 1305], [696, 108, 586, 176, 610, 1470, 1080, 101, 152, 92, 1252, 101, 1603, 1576, 822, 827, 651, 418, 614, 1736, 604, 1130], [986, 1029, 1245, 1305, 285, 101, 100, 580, 1711, 825, 75, 822, 603, 216, 1585, 1209, 308, 1137, 344, 666, 800, 825, 1262, 610, 950, 1133, 866, 638, 993, 1639, 165, 1474, 730], [1549, 1661, 916, 815, 586, 610, 509, 1185, 950, 916, 906, 1305, 580, 993, 1142, 1474, 354, 802, 993, 428, 509, 993, 400, 841, 1585, 1209, 768, 604, 1279, 811, 284, 129, 1474, 1344, 1762, 563, 1681, 331, 101, 1209, 1070, 1396, 1209, 295, 273, 1305, 932], [1521, 330, 916, 1071, 1177, 152, 337, 1585, 1121, 232, 752, 1121, 586, 98, 571, 101, 216, 614, 997, 1133, 1296, 216, 1766, 1305, 449, 1676, 802, 1263, 610, 1474, 687, 818, 1285, 799, 105, 1285, 799, 1585, 1101], [1285, 1305, 175, 610], [152, 449, 484, 421, 930, 152, 1161, 604, 610, 152, 449, 1450, 799, 283, 1322, 336, 153, 246, 916, 1767, 586, 55, 1509, 875, 336, 357, 1474, 1595, 1188, 1313, 1182, 101, 152, 1718, 29, 152, 164, 1184, 822, 1022, 802, 728, 984, 1322, 1480], [992, 1563, 620, 604, 1419, 683, 1655, 1511, 705, 916, 374, 1474, 535, 1071, 1077, 993, 263, 101, 202, 578, 619, 872, 1474, 796, 604, 705, 950, 789, 1519, 1257, 825, 468, 1391, 1734, 32, 825, 152, 921, 604, 799], [1474, 1228, 1711, 504, 353, 1474, 1233, 250, 1305, 715, 996, 1678, 632, 1305, 1332, 610, 937, 449, 638, 152], [1474, 1228, 1711, 504, 353, 1474, 1233, 250, 1305, 715, 996, 1678, 632, 1305, 1332, 610, 937, 449, 638, 152], [280, 1436, 476, 431, 1467, 152, 857, 1031, 1305, 1256, 600, 421, 154, 1305, 115, 1711, 152, 1066, 1305, 418], [610, 1585, 1158, 1322, 687, 1672, 297, 1474, 152, 1495, 1407, 421, 887, 1474, 298, 1332, 216, 130], [1305, 1076, 610, 1474, 317, 1213, 1439, 1302, 586, 1412, 125, 1210, 1765, 1585, 843, 1397, 1489, 101, 152, 392, 1209, 706, 705, 1412, 1491, 1474, 42, 731, 1486, 24, 1133, 233, 929, 1285], [696, 426, 916, 1719, 166, 741, 1305, 993, 1283, 950, 916, 1629, 1692, 1305, 830, 395, 1066, 1305, 152, 1205, 683, 993, 1694, 727, 1628, 32, 993, 127, 1585, 126, 1625, 610, 1585, 286, 2, 457, 787], [1585, 825, 1407, 1750, 54, 645, 342, 1524, 610, 604, 798, 298, 980, 841], [171, 743, 798, 916, 152, 408, 604, 152, 1515, 798, 916, 152, 1241, 604, 152, 1407, 173, 588, 845, 802, 1209, 427, 509, 1209, 1456, 101, 1727, 1711, 1235, 1474, 1389, 1514, 535, 1008, 1305, 1109, 993, 149, 1359, 604, 1202, 915, 610, 1474, 612], [683, 1322, 726, 773, 745, 101, 152, 1188, 152, 966, 425, 432, 418, 563, 1348, 242, 326, 365, 481, 101, 152, 1188, 1113, 1322, 1188, 586], [1396, 563, 1722, 1704, 799, 1585, 1341, 683, 152, 433, 27, 789, 1310, 683, 610, 1133, 452, 1711, 152, 1658, 91, 216, 151, 850, 1256, 1361, 825, 367, 1305, 12, 297, 754, 1292, 809, 19, 1474, 1136, 1209, 1736, 802, 798], [101, 1040, 604, 1131, 1566, 63, 418, 1605, 1188, 1313, 1182, 101, 1646, 255, 671, 1435, 604, 491, 556, 825, 854, 604, 152, 558, 1761, 604, 822, 152, 214, 1620, 1280, 485, 535, 703, 1209, 1331, 638, 152, 271, 141, 1484, 152, 610], [1305, 1076, 610, 1474, 317, 1213, 1439, 1302, 586, 1412, 125, 1210, 1765, 1585, 843, 1397, 1489, 101, 152, 392, 1209, 706, 705, 1412, 1491, 1474, 42, 731, 1486, 24, 1133, 233, 929, 1285], [604, 297, 537, 101, 1213, 1391, 604, 1652, 1193, 1007, 825, 1067, 327, 1592, 1, 54, 747, 604, 653, 1638, 298, 1256, 343, 802, 993, 504], [995, 1285, 298, 421, 1269, 1327, 152, 897, 1524, 101, 1285, 298, 421, 101, 1209, 1492, 1237, 1260, 835, 518, 565], [101, 545, 116, 513, 402, 152, 1192, 647, 140, 1083, 104, 378, 1476, 1074, 1062, 1501, 705, 1209, 1211, 1524, 610, 21, 873, 104, 977, 1313, 1166, 846, 822, 152, 1458, 226, 140], [485, 399, 1305, 304, 1322, 469, 1499, 1019, 634, 916, 1405, 1188, 825, 152, 1684, 1305, 686, 668, 1595, 449, 610, 1559, 1305, 95, 378, 610, 146, 1305, 256], [1219, 916, 1377, 384, 633, 1734, 1395, 535, 1008, 1519, 516, 899, 101, 1565, 1474, 1360, 841], [1559, 1305, 792, 1585, 670, 802, 798, 418, 152, 469, 610, 586, 792, 1121, 1742, 747, 604, 282, 1104, 1122, 418, 521, 915, 320, 316, 1426, 24, 309, 1305, 925, 817, 1687, 418, 683, 604, 1322, 1337], [216, 767, 640, 317, 327, 1533, 1188, 518], [1396, 1585, 152, 1048, 825, 301, 1677, 101, 961, 257, 418, 1396, 1601, 535, 574, 1428, 101, 855, 799, 424, 3, 1331, 586, 1120, 1423], [610, 1730, 635, 586, 1697, 1687, 1474, 884, 888, 1196, 152, 1175, 981, 101, 687, 1398, 101, 1209, 1331, 101, 369, 421, 450, 1689, 1305, 535, 681, 1447, 518, 586, 152], [563, 859, 418, 1561, 1743, 1305, 897, 850, 819, 825, 1209, 407, 1570, 604, 1375, 910, 1051, 1305, 1472, 101, 99, 1193, 606, 604, 903, 802, 1409, 478, 1360, 152, 597, 1612], [1723, 982, 475, 64, 152, 1519, 1492, 1305, 580, 280, 1474, 1711, 103, 1585, 1305, 1256, 1183, 1021, 378, 925, 152, 473, 1474, 897, 1524, 610, 1663, 1442, 1474, 1442, 152, 1402, 773, 802, 216, 84, 297, 43, 152, 1700, 916, 789, 1322, 499], [152, 914, 307, 1711, 859, 799, 1536, 1259, 449, 972, 604, 951, 586, 1209, 706, 625, 1305, 36, 1262, 418, 112, 1360, 449], [653, 1000, 604, 152, 1515, 378, 1412, 192, 604, 1412, 1579, 996, 580, 101, 481, 891, 1066, 1305, 610, 653, 640, 1256, 1408, 1140, 1131, 705, 1209, 1030, 1189, 604, 1322, 540, 194, 845, 1305, 1633, 1352, 397, 1400, 135, 653, 793], [216, 446, 649, 152, 1741, 604, 18, 1474, 751, 1064, 615, 683, 27, 576, 1305, 749, 610, 1474, 661, 604, 216, 282, 1291, 929, 449, 638, 698, 1064, 405, 1360, 449], [229, 288, 1474, 1013, 542, 473, 1349], [817, 10, 1699, 1415, 1029, 152, 203, 1519, 604, 10, 682, 654, 1372, 218, 432, 802, 884, 682, 1734, 1322, 1123, 802, 127, 885, 1585, 152, 1478, 978, 802, 10, 356, 610, 1585, 1168, 1661, 802, 515, 1202, 127, 719], [586, 1305, 152, 1305, 152, 58, 1193, 984, 777, 152, 1407, 535, 1093, 1305, 358, 604, 449, 1188, 298, 317, 58, 897, 1473, 974, 1249, 32, 202, 58, 145, 491, 1474, 1380, 1400], [448, 216, 1585, 1322, 1431, 216, 1585, 1322, 871, 1362, 213, 1457, 1305, 1732, 563, 452, 1305, 610, 1021, 378, 12, 530, 1322, 1188, 1209, 628, 1360, 449], [67, 798, 249, 1360, 449, 638, 941, 989, 1474, 551, 421, 850, 1732, 563, 452, 1305, 610, 152, 449, 798, 249, 901], [1562, 378, 290, 938, 88, 1323, 1304, 41, 586, 698, 610, 101, 152, 629, 604, 563, 1399, 669, 101, 106, 1008, 574, 611, 1305, 12, 579, 1587, 385, 799, 998, 1285, 388, 719, 1387, 1468, 661, 604, 88, 653], [1362, 213, 1309, 58, 1177, 286, 67, 798, 249, 929, 449, 638, 941, 989, 1474, 551, 421, 850, 1732, 563, 452, 1305, 610, 152, 449, 798, 249, 901], [610, 604, 220, 917, 1145, 105, 785, 378, 1731, 814, 590, 575, 492, 101, 152, 205, 748, 546, 1305, 1574, 1459, 1624, 541], [1305, 1016, 1322, 1459, 908, 1147, 152, 401, 604, 912, 1305, 687, 1345, 1474, 1641, 610, 1360, 449], [884, 1677, 1585, 1350, 438, 984, 1745, 1698, 916, 1303, 473, 761, 297, 216, 1585, 1717, 1321, 551, 421, 916, 1284, 802, 563, 388, 1599, 1623, 1743, 1305, 340, 610, 1360, 449, 101, 1322, 1295, 1583], [48, 165, 586, 93, 101, 378, 218, 1209, 997, 1289, 1305, 185, 944, 604, 610, 1474, 805, 117, 101, 152, 1035], [709, 1670, 1621, 1385, 683, 378, 1720, 1721, 563, 709, 1670, 435, 1711, 1480, 1511, 705, 30, 1649, 1583, 30, 1387, 686, 1057, 1474, 1373, 101, 1338, 610, 1256, 1730, 418, 889, 728, 1546, 164, 339, 535, 798, 1293, 1621, 1650], [1585, 825, 1407, 1750, 54, 645, 342, 1524, 610, 604, 798, 298, 980, 841], [1284, 825, 1305, 1275, 705, 1209, 1137, 690, 1315, 817, 1347, 1234, 128], [152, 1489, 604, 432, 27, 1209, 500, 823, 825, 152, 1337, 1305, 898, 432, 798, 154, 1412, 1145, 298, 1296, 1305, 610, 1734, 32, 915, 302, 711, 1474, 434, 152, 453, 1474, 1729, 1305, 889, 683, 432, 1305, 544, 799, 1031, 1305, 845], [388, 1592, 391, 916, 380, 1474, 884, 888, 334, 1678, 152, 1407, 152, 887, 175, 562, 1209, 34, 1223, 1474, 577, 1172, 1469, 1360, 449, 586, 1322], [680, 535, 574, 1576, 822, 610, 1474, 152, 802, 1474, 1524, 1477, 570, 822, 216, 280, 595, 1115, 1005, 1285, 247, 798, 96, 638, 610], [101, 1322, 639, 1666, 878, 916, 223, 1132, 440, 1585, 384, 127, 682, 418, 10, 1489, 1350, 610, 1489, 418, 870, 1305, 445, 719, 1585, 1350, 276, 170, 16, 1303, 297, 449, 650], [1734, 1585, 827, 861, 101, 207, 1305, 1097, 1305, 695, 175, 1581, 610, 464, 189, 236, 1029, 247, 678, 111, 798, 1021, 321, 1305, 1182, 1566, 1188, 984, 802], [825, 565, 152, 1133, 279, 825, 1209, 906, 870, 857, 1711, 254, 152, 1542, 965, 101, 1585, 299, 292, 825, 972, 1209, 1365, 900, 33, 1333, 1711, 1474, 747, 604], [610, 1585, 1717, 604, 152, 621, 1432, 1751, 518, 1494, 1650, 653, 916, 604, 1529, 1759, 152, 622, 1079, 1391, 825, 1515, 1103, 152, 1386, 604, 1081], [111, 152, 1457, 1305, 1296, 152, 1262, 588, 799, 850, 38, 586, 281, 1575, 1051, 1378, 1474, 1277, 822, 984, 1682, 604, 152, 1238, 107, 152, 1627, 206, 1585, 374], [1559, 1305, 1519, 5, 1480, 1673, 563, 205, 604, 473, 217, 152, 1266, 604, 1356, 370, 504, 897, 497, 1305, 452, 610, 1333, 1305, 776, 1396, 247, 798, 1403, 916, 152, 341, 732, 1412, 1118], [216, 1204, 378, 591, 136, 1240, 1585, 1065, 1141, 1209, 460, 1566, 419, 581, 586, 254, 1065, 172, 1474, 146, 1209, 181, 208, 1524, 610, 101, 267, 604, 152, 1523, 604, 152, 1690, 604, 469, 1474, 1633, 1740, 868], [1236, 293, 714, 270, 1749, 1305, 897, 610, 152, 764, 1133, 1519, 425, 271, 1480, 509, 700, 1305, 300, 1711, 1209, 511, 1305, 1355, 1577, 610, 101, 993, 1489, 1474, 1238, 1186, 518, 822, 152, 1459], [1711, 27, 156, 1209, 424, 856, 1305, 510, 152, 897, 1524, 610, 418, 948, 101, 216, 56, 1585, 45, 518, 101, 856, 1711, 1474, 1711, 1209, 406, 342, 604, 1261, 215, 1131], [454, 1322, 1656, 1474, 280, 1367, 473, 729, 1461, 1630, 507, 432, 1474, 915, 1238, 377, 1474, 261], [216, 1234, 1138, 799, 1585, 922, 1305, 1182, 1474, 1703, 1188, 101, 216, 359, 421, 247, 962, 421, 298, 1305, 925, 1322, 142, 1188, 586, 1474, 327, 424, 1188, 1305, 570, 785, 1322, 1412], [1196, 152, 687, 818, 506, 378, 205, 604, 1257, 1585, 848, 24, 586, 1474, 521, 1474, 1479, 1412, 29, 109, 929, 449, 638, 216, 536, 506], [533, 1554, 101, 554, 1482, 1452, 860, 1274, 1668, 1254, 825, 1285, 1305, 1644, 1711, 152, 1737, 604, 1540, 993, 743, 1305, 743, 1118, 705, 1753], [152, 1739, 879, 1585, 1717, 604, 152, 341, 1264, 1634, 825, 152, 1337, 1734, 799, 378, 1367, 1159, 802, 10, 418, 1099, 608, 604, 216, 1585, 465, 1305, 1209, 53, 550, 640, 1256, 1756, 604, 152, 219], [610, 968, 493, 916, 1689, 1305, 1058, 449, 1676, 1303, 297, 101, 152, 1407, 799, 1585, 789, 1015, 799, 1585, 1209, 1187], [816, 704, 604, 884, 1590, 1384, 747, 804, 610, 1497, 568, 1474, 1124], [799, 378, 1650, 653, 425, 1209, 1538, 1384, 802, 1014, 1209, 678, 60, 683, 1170, 382, 518, 1735, 144, 1474, 1172, 1585, 32, 816, 1305, 1014, 563, 364], [1421, 1305, 1434, 1177, 1285, 610, 117, 1014, 418, 282, 665, 152, 1543, 1661, 421, 984, 1364, 1657, 1650, 1585, 421, 1651, 1305, 1716, 1285, 610, 1585, 170, 1322, 1531, 655, 101, 1209, 424, 908], [10, 611, 705, 1658, 1058, 802, 101, 1322, 432, 1238, 1186, 27, 576, 1305, 610, 418, 282, 747, 101, 1539, 974, 152, 429, 421, 298, 925, 1014, 518, 1061, 1322, 722, 1661, 1305, 691, 825, 837, 509, 1168, 481, 825, 1325, 861, 970], [1650, 1585, 1021, 378, 538, 152, 636, 39, 409, 152, 341, 810, 1108, 1191, 323, 1676, 1162, 333, 452, 152, 610, 452, 152, 895, 642, 598, 710, 449, 553, 1021, 378, 175, 216, 295, 1191, 586, 1738], [485, 249, 485, 850, 1256, 227, 1089, 825, 66, 1474, 1394, 1474, 1696, 485, 1578, 1028, 1027, 1279, 825, 152, 823, 604, 610, 1546, 133, 143, 1087, 496, 1578, 1308, 485, 96, 974, 485, 298, 1315, 799, 1305, 133, 1275, 604, 376, 485, 298, 866, 638, 276], [1148, 460, 849, 1767, 1091, 1242, 101, 305, 1474, 658, 653, 101, 1346, 1548, 1255, 1662, 1474, 554, 421, 916, 825, 260, 1474, 101, 1371, 262, 1380, 352, 604, 735, 1305, 404, 1322, 1340, 802, 932, 449, 936], [264, 382, 610, 1585, 152, 1478, 978, 604, 610, 101, 152, 1210, 10, 336, 1220, 1474, 1153, 916, 1371, 604, 152, 345, 1659, 398, 216, 521], [1453, 1757, 1052, 535, 703, 563, 474, 1232, 1305, 480, 1474, 152, 124, 1180, 1747, 1305, 137, 1623, 825, 1170, 1262, 610, 1360, 799, 841], [1206, 535, 574, 1528, 822, 487, 1474, 101, 181, 638, 610, 950, 32, 1008, 1209, 588, 1305, 1403, 638, 1396, 950, 1536, 111, 1209, 1070, 1339, 101, 993, 28], [1474, 101, 653, 916, 253, 688, 964, 1066, 1305, 610, 1711, 342, 586, 916, 1267, 1711, 504, 101, 1653, 1305, 1754, 1082, 974, 561, 1426, 746, 1305, 317, 782, 1406, 825, 1188, 705, 1209, 405, 604, 1729], [799, 378, 1134, 653, 1474, 993, 504, 232, 916, 71, 101, 1564, 998, 518, 610, 950, 1313, 1045, 518, 1420, 297, 683, 1116, 152, 653, 623, 1508, 610, 1585, 70], [610, 604, 152, 429, 1474, 1607, 604, 152, 888, 604, 370, 297, 520, 1726, 802, 1011, 604, 805, 49, 1068, 1328], [1322, 653, 916, 487, 1305, 1371, 1708, 810, 1437, 974, 152, 1411, 73, 305, 1322, 653, 1585, 1538, 1305, 786, 152, 522, 1617, 235, 1285, 298, 864, 1474, 877, 317, 1434, 1177, 493, 509, 1360], [216, 1701, 460, 1566, 132, 1585, 1263, 610, 101, 602, 1474, 762, 797, 1305, 1059, 1188, 1474, 1014, 610, 1585, 1717, 604, 152, 621, 741, 1305, 282, 825, 152, 1337, 644, 841], [431, 1074, 152, 689, 604, 127, 1119, 892, 85, 495, 793, 1053, 488, 1114, 152, 1597, 687, 523, 1597, 610, 152, 341, 928, 604, 1014, 1519, 1162, 825, 1114, 1407, 1123, 518, 1168, 266, 1305, 1661, 789, 297, 1471, 1209, 689, 1712, 798, 309], [101, 517, 1305, 925, 1032, 586, 1504, 274, 421, 887, 304, 152, 1160, 1591, 1384, 747, 1474, 1628, 974, 1451, 421, 887, 434, 1431, 1407, 1460, 1305, 930, 448, 1623, 1305, 686, 1504, 274], [1014, 1585, 1440, 518, 610, 744, 1585, 1609, 1711, 152, 324, 802, 152, 180, 604, 1219, 653, 156, 101, 1305, 1392, 1744, 1623, 1305, 925, 232, 653, 1474, 993, 1437], [429, 370, 120, 1726, 1047, 107, 215, 610], [1585, 825, 1407, 1750, 54, 645, 342, 1524, 610, 604, 798, 298, 980, 841], [789, 1519, 1585, 1643, 799, 378, 32, 1014, 1670, 1474, 610, 906, 1474, 683, 378, 923, 1305, 1016, 216, 929, 449, 841], [460, 916, 1528, 638, 1285, 152, 1569, 1208, 1585, 101, 840, 1066, 1305, 1588, 1474, 610, 950, 1625, 1305, 247, 923, 638, 799, 54, 1651, 1305, 1027, 458, 1305, 152, 1033, 1474, 1190, 232, 295, 573], [1418, 967, 1521, 1100, 1245, 351, 1567, 683, 1112, 1585, 1730, 805, 766, 1075, 134, 1445, 1144, 948, 805, 1178, 1178, 1178, 789], [683, 896, 1480, 916, 1767, 586, 215, 1474, 916, 1381, 414, 421, 342, 604, 1583, 758, 1474, 529, 683, 984, 1583, 1298, 27, 1231, 823, 825, 152, 929, 449, 16], [152, 58, 1054, 296, 825, 318, 737, 951, 683, 733, 822, 1209, 65, 662, 1305, 152, 469, 698, 610, 1585, 363, 152, 1337, 1474, 1350, 24, 1319, 1209, 424, 1686, 101, 152, 58, 480, 1457, 1305, 818, 216, 1305, 929, 449], [947, 1401, 1329, 648, 216, 17, 575, 356, 518, 836, 784, 1591, 152, 610, 1474, 1070, 967, 740], [952, 798, 802, 152, 206, 1734, 551, 247, 798, 399, 1305, 314, 152, 569, 419, 823, 604, 1210, 586, 817, 243, 701, 405, 1210, 1742, 774, 152, 610, 683, 336, 1220, 592, 192, 798, 1748, 314, 799, 1758, 1305, 1312, 1371, 1165, 755], [1706, 884, 1742, 604, 610, 804, 1330, 737, 1210, 1765, 615, 1220, 9, 1474, 1181, 960, 317, 58, 925, 1322, 1337, 1650, 405, 152, 1407, 258], [386, 234, 107, 311, 215, 429, 610, 1441, 610, 1133, 736, 328, 152, 1718, 604, 1262, 1092, 802, 449, 442], [460, 535, 574, 1134, 518, 1414, 1083, 152, 1407, 604, 560, 950, 535, 574, 1528, 638, 610, 1474, 1285, 421, 298, 12, 678, 555, 1305, 317, 1322, 469, 418, 152, 1407], [687, 818, 1585, 1114, 518, 610, 759, 1585, 1519, 1492, 1305, 818, 216, 1343], [1755, 419, 1345, 101, 254, 216, 1702, 867, 1133, 1654, 604, 254, 378, 341, 455, 419, 1345, 1473, 915, 439, 1412, 888, 418, 152, 117, 604, 610, 565, 1243, 463, 603, 943, 1294, 822], [1285, 1585, 152, 1451, 1273, 1691, 1711, 610, 1474, 152, 1530, 604, 370, 297, 101, 152, 429, 1209, 541, 1592, 825, 1209, 289, 1024], [144, 604, 418, 916, 1506, 152, 568, 604, 152, 302, 157, 772, 418, 1330, 418, 152, 948, 604, 1417, 1218, 8, 1305, 509, 193, 1336, 791, 61, 604, 1412, 1342, 418, 698, 610], [161, 984, 1094, 1711, 610], [101, 563, 1604, 918, 825, 624, 101, 1558, 880, 780, 1098, 1571, 1640, 110, 378, 469, 1499, 1573, 920, 27, 828, 152, 524, 634, 802, 739, 1305, 897, 610, 101, 152, 429, 934, 216, 346], [1204, 485, 69, 1305, 12, 1209, 1151, 192, 1067, 584, 216, 1204, 825, 372, 1489, 101, 851, 1474, 1572, 257, 164], [254, 1474, 1127, 916, 276, 241, 152, 1139, 897, 1524, 610, 424, 1343, 586, 1006, 683, 678, 1598, 586, 874, 1474, 724, 604, 1589, 228, 1714, 1019, 322, 850, 929], [711, 422, 1209, 816, 51, 101, 152, 897, 1524, 518, 1025, 1412, 1491, 1305, 317, 782, 610, 418, 518, 384, 152, 540, 183, 148, 604, 667, 929, 449, 638, 711, 418, 101, 1322, 1374], [216, 1331, 1430, 1176, 820, 694, 822, 1667, 610, 604, 152, 429, 1446, 765, 825, 1375, 1084, 518, 152, 1305, 1647, 1238, 1186, 586, 429, 610], [473, 205, 268, 813, 1532, 333, 930, 563, 1167, 1623], [152, 473, 27, 1169, 574, 265, 1711, 599, 1734, 421, 1421, 1305, 818, 683, 232, 136, 11, 101, 254, 916, 825, 1209, 730, 1305, 1618, 716, 610, 1474, 1014, 895], [822, 335, 1688, 1209, 1021, 378, 1390, 102], [1711, 152, 424, 596, 983, 393, 825, 1520, 298, 940, 1131, 604, 818, 1678, 152, 1379, 1716, 152, 1616, 1158, 801, 604, 821, 969, 152, 967, 604, 618, 260, 610, 1474, 608, 449], [361, 378, 607, 430, 916, 1367, 1095, 518, 483, 418, 750, 1585, 420, 1209, 424, 576, 56, 683, 1133, 925, 197, 418, 1437, 544, 950, 916, 341, 1440], [418, 456, 320, 535, 576, 1305, 747, 418, 432, 1619, 101, 152, 152, 1660, 27, 1228, 1192, 418, 1305, 1018, 101, 449, 687, 0, 432, 1489, 1129], [1585, 825, 1407, 1750, 54, 645, 342, 1524, 610, 604, 798, 298, 980, 841], [101, 705, 467, 604, 152, 794, 604, 1602, 957, 451, 518, 1209, 1352, 933, 101, 1173, 1305, 925, 152, 1569, 1208, 705, 610, 418, 1330, 1535, 1209, 166, 2, 152, 794, 1226, 152, 1569, 1208, 378, 788], [152, 778, 706, 1591, 636, 39, 1046, 418, 1207, 64, 1585, 1209, 831, 1291, 802, 118, 138, 1734, 1440, 518, 610, 418, 1185, 113, 1044, 1511, 705, 1393, 636, 39, 418, 824, 663, 993, 143, 795, 802, 325], [1595, 1568, 604, 1517, 1541, 1711, 707, 368, 1131, 604, 1091, 62, 604, 610, 101, 351, 1201, 586, 1514, 916, 1169, 1076, 1106, 1305, 37, 254], [1322, 1481, 1717, 889, 1717, 1070, 643, 1615, 883, 802, 1740, 517, 659, 907, 657, 883, 421, 196, 199, 1209, 1070, 1305, 1256, 1449, 1305, 1076, 610, 1474, 925, 1322, 295, 1337, 446, 518, 1606, 242], [971, 247, 798, 1421, 1305, 929, 638, 1285, 687, 818, 1474, 610, 916, 77, 1036, 186, 128, 152, 614, 1755, 822, 1322, 1265, 1711, 1474], [361, 378, 607, 430, 916, 1367, 1095, 518, 483, 1474, 1585, 420, 1209, 424, 576, 56, 683, 1133, 925, 197, 1474, 1437, 544, 950, 916, 341, 822, 198], [1262, 1070, 747, 298, 1029, 14, 586, 232, 1357, 527, 672, 413], [135, 1322, 1337, 1730, 175, 610, 1474, 239, 302], [1284, 984, 1195, 1105, 1266, 604, 1081, 1585, 1525, 1305, 490, 1279, 1669, 802, 1224, 769, 1078, 1557, 1081, 1305, 317, 185, 944, 604, 685, 1474, 610, 929, 449, 841], [930, 1413, 1412, 1724, 1099, 1526, 74, 473, 1104, 789, 1220, 1416, 834, 687, 818, 1006, 683, 1209, 881, 1209, 1464, 1614, 1729, 1281, 152, 1128], [952, 798, 1217, 802, 218, 152, 1272, 1516, 504, 56, 1474, 855, 610, 631, 1070, 1405, 916, 802, 1474, 1014, 1474, 1305, 686, 750, 1474, 514], [687, 818, 1585, 563, 198, 683, 1713, 1276, 1678, 44, 1209, 1121, 212, 604, 916, 757, 641, 216, 198, 101, 993, 178, 27, 817, 131, 1084, 656, 1305, 247, 54], [498, 347, 1114, 604, 152, 575, 826, 1305, 1711, 152, 705, 1209, 604, 406, 406, 1107, 1305, 697, 1521, 512, 586, 512, 1305, 1114, 799, 81], [152, 230, 880, 371, 247, 904, 869, 152, 379, 604, 1322, 679, 1474, 437, 101, 152, 876, 604, 610, 1474, 483, 683, 1066, 1305, 204, 637, 321, 1305, 1580, 1322, 341, 461, 1155], [327, 1188, 1474, 925, 481, 489, 1157, 950, 1133, 925, 1474, 425, 342, 1305, 817, 469, 1474, 1001, 309, 1595, 1305, 610, 1474, 1090, 827, 567, 604, 1188, 327, 1070, 1305, 1059, 1322, 469, 1059, 1322, 1337, 1474, 1305, 1059, 1306], [327, 1188, 1474, 925, 481, 489, 1157, 950, 1133, 925, 1474, 425, 342, 1305, 817, 469, 1474, 1001, 309, 1595, 1305, 610, 1474, 1090, 827, 567, 604, 1188, 327, 1070, 1305, 1059, 1322, 469, 1059, 1322, 1337, 1474, 1305, 1059, 1306], [327, 1188, 1474, 925, 481, 489, 1157, 950, 1133, 925, 1474, 425, 342, 1305, 817, 469, 1474, 1001, 309, 1595, 1305, 610, 1474, 1090, 827, 567, 604, 1188, 327, 1070, 1305, 1059, 1322, 469, 1059, 1322, 1337, 1474, 1305, 1059, 1306], [1248, 518, 1133, 12, 798, 845, 586, 1305, 905, 1288, 1062, 913, 1306, 901, 152, 133, 1519, 775, 518, 1600, 705, 1209, 60, 604, 152, 844, 610, 1742, 1622, 518, 1640, 57, 1521, 1149, 518], [421, 535, 1578, 613, 1319, 1305, 1305, 609, 1322, 300, 540, 593, 802, 1009, 1070, 1449, 1209, 617, 604, 540, 1133, 1256, 188, 101, 152, 429, 1035, 631, 540, 593, 378, 717, 610, 397], [771, 1496, 172, 40, 101, 462, 604, 951, 1350, 610, 418, 884, 888, 334, 777, 152, 329, 128, 58, 216, 1240, 528, 1560, 1305, 1611, 1209, 1204, 604, 1623, 86, 1725, 1305, 1296, 825, 687, 1474, 1345], [610, 1585, 1297, 653, 1678, 152, 1407, 586, 152, 429, 1305, 1693, 1474, 152, 76, 1305, 841, 101, 152, 634, 421, 298, 1029, 547, 1305, 366, 351, 449, 461, 197, 930, 1623], [720, 1711, 1253, 1585, 1287, 1734, 101, 110, 799, 27, 1045, 563, 1438, 419, 523, 683, 101, 221, 1305, 152, 315, 356, 518, 610, 924, 1305, 217, 152, 1266, 604, 22, 1585, 1158, 152, 687, 604, 984, 805, 634, 1474, 1540, 152, 1273], [313, 1734, 152, 1279, 916, 1635, 1658, 737, 152, 1595, 1114, 604, 610, 1474, 1384, 59, 1478, 572, 1305, 1262, 1092, 939, 111, 798, 450, 1192, 652], [1209, 1433, 60, 683, 610, 1585, 789, 1578, 638, 1188, 1711, 1740, 1070, 683, 798, 1182, 798, 916, 363, 1040, 604, 1142, 83, 1711, 799, 993, 150, 1318, 432, 438, 962, 1717, 298, 46, 333, 327, 327, 1096], [160, 535, 1767, 1209, 601, 319, 1189, 604, 1658, 1437, 535, 1544, 101, 1131, 1474, 152, 894, 1585, 1020, 309, 548, 1359, 604, 187, 737, 610, 187, 294, 320, 160, 713, 604, 394, 470], [1099, 1099, 1282], [1324, 1431, 421, 916, 1284, 1177, 1305, 1056, 421, 298, 247, 54, 608, 449, 1549, 421, 1732, 417, 1083, 594, 216, 1585, 1362, 378, 1431, 216, 1322, 871, 1362, 213, 1457, 1305, 1732, 563, 452, 1305, 610, 1021, 378, 12, 530, 1322, 1188, 1209, 628], [886, 336, 1220, 1489, 1550, 282, 1734, 799, 552, 1029, 535, 1305, 1256, 216, 1492, 587, 378, 1454, 27, 1300, 1737, 1305, 925, 1014, 1595, 1595, 424, 1405, 825, 1636, 305, 350, 1338, 698, 1185], [1218, 808, 802, 1441, 1350, 418, 718, 1305, 1390, 563, 1487, 1133, 1527, 1042, 68, 802, 1441, 626, 1474, 718, 1305, 1390, 1209, 1273, 245, 946, 1744, 1270, 716, 610, 563, 955, 383, 1680], [640, 817, 1194, 1256, 1278, 1305, 431, 1480, 298, 12, 799, 1709, 388, 234, 954, 1463, 604, 1043, 950, 1313, 861, 825, 468, 509, 1159, 1412, 859, 388, 1258, 1585, 994, 858], [310, 1490, 687, 165, 1711, 721, 1466, 1448, 708, 1246, 152, 708, 812, 101, 721, 1763, 410, 604, 320, 610, 1474, 1547, 604, 1209, 699, 803, 1181, 705, 1744, 893, 1732, 687, 397, 825, 577], [111, 1209, 1216, 1514, 996, 1209, 1070, 509, 1645, 715, 418, 434, 1209, 1675, 509, 563, 1658, 509, 1209, 201, 1674, 781, 799, 799, 1585, 807, 705, 990, 23, 781, 1637, 534, 251, 403, 486, 421, 241, 610, 661, 604, 1663, 692, 604, 1014, 1305, 287, 739], [543, 158, 518, 123, 902, 472, 973, 1542, 1422], [1760, 162, 147, 1585, 789, 1715, 152, 935, 1427, 604, 1262, 1092, 1474, 687, 818, 518, 863, 610, 705, 1209, 627, 802, 152, 1311, 979, 225, 32, 817, 1251, 1038, 1029, 858, 705, 798, 312, 1029, 1209, 1593, 447, 1474, 247, 1396, 485, 309, 1346], [610, 1474, 141, 916, 1371, 604, 152, 470, 604, 152, 1314, 874, 378, 341, 859, 419, 995, 1145, 31, 1305, 942, 1209, 40, 632, 604, 338, 629, 1557, 1360, 152, 1627, 1331]]\n",
            "[[1595, 1019, 1085, 890, 1679, 798, 416, 1178, 1631, 1452, 482, 604, 471, 482, 604, 1060, 987, 1250, 610, 1388, 1705, 1578, 802, 563, 853, 882, 604, 1131], [552, 1029, 1730, 179, 842, 396, 604, 610, 850, 789, 1256, 449, 1676, 396, 604, 1197, 1021, 378, 58, 1000, 1322, 360, 1711, 1418, 87, 473, 90, 799, 378, 817, 167, 509, 985, 566, 652, 216, 1730, 1671, 1133, 135, 798, 1169, 696], [373, 238, 1585, 210, 502, 1301, 825, 1353, 1330, 1474, 589, 1069, 502, 1268, 1585, 1101, 1305, 411, 474, 1037, 604, 1285, 610, 1427, 152, 325, 604, 1353, 89, 525], [696, 426, 298, 1256, 1304, 101, 204, 150, 665, 1219, 653, 418, 790, 152, 388, 887, 247, 805, 1756, 1305, 925, 232, 150, 418, 993, 282, 518, 674, 1209, 53, 388, 610, 550], [291, 1556, 1595, 884, 823, 825], [216, 640, 317, 802, 155, 1055, 298, 32, 535, 1209, 1215, 604, 838, 712, 1455, 1083, 531, 582, 610, 988, 1307, 509, 1256, 296, 1608, 1536, 168, 275, 999, 111, 675], [1493, 161, 441, 459, 1761, 604, 1049, 418, 159, 1537, 1425, 152, 148, 604, 1522, 1594, 976, 1305, 1221, 1397, 432, 1369, 1377, 152, 244, 604, 1209, 1376, 1632, 1145, 693, 1305, 911, 610, 1474, 1461, 504], [388, 1074, 1146, 870, 115, 1209, 1225, 13, 869, 1074, 1156, 1305, 175, 829, 1305, 152, 115, 101, 1356, 604, 1317, 1485, 1512, 1711, 152, 1431, 1305, 340, 152, 857, 444, 610, 1585, 664], [610, 1133, 1256, 152, 452, 604, 884, 1648, 444, 421, 1732, 563, 452, 1305, 610], [485, 298, 1029, 1483, 421, 916, 748, 1061, 216, 610, 1474, 661, 604, 152, 429, 1511, 295, 259, 47, 1661, 1474, 996, 1188, 683, 298, 1256, 611, 802, 927, 544, 916, 421, 605, 310, 1227, 355], [1396, 216, 984, 539, 1746, 1101, 825, 101, 1322, 1660, 485, 854, 1322, 1305, 930, 1623, 1524, 481, 1514, 984, 916, 210, 216, 539, 1746, 421, 535, 1305], [789, 1528, 152, 1551, 1566, 1601, 949, 916, 421, 444, 798, 865, 567, 1404, 1368, 1474, 1230, 1710, 175, 610, 216, 1275, 1133, 135, 825, 1121, 1474, 1285, 1214, 1585, 799, 1305, 1088, 1209, 15, 1471, 1676, 1488, 1004, 1474, 928, 1595, 1429, 509, 799, 850, 1256]]\n",
            "[1.   1.   0.75 0.75 0.75 1.   1.   0.75 0.75 0.75 0.75 0.75 0.75 0.75\n",
            " 0.75 0.75 0.75 0.75 1.   1.   0.75 1.   0.75 0.75 1.   1.   0.75 0.75\n",
            " 0.75 1.   1.   0.75 1.   1.   0.75 0.75 1.   1.   0.75 0.75 1.   0.5\n",
            " 0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5\n",
            " 0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5\n",
            " 0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5\n",
            " 0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5\n",
            " 0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5\n",
            " 0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5\n",
            " 0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5\n",
            " 0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5\n",
            " 0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5\n",
            " 0.5  0.25 0.25 0.   0.   0.25 0.25 0.25 0.25 0.   0.   0.   0.25 0.25]\n",
            "[1.   1.   1.   0.75 0.5  0.5  0.5  0.5  0.25 0.   0.   0.  ]\n",
            "182\n",
            "(182, 1768)\n",
            "(182,)\n",
            "12\n",
            "(12, 1768)\n",
            "(12,)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               226432    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 16)                2064      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 228,513\n",
            "Trainable params: 228,513\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "41 128 13\n",
            "Augmented Dataset X :  (90, 1768)\n",
            "Augmented Dataset y :  (90,)\n",
            "Augmented Dataset X[75] :  [0. 0. 0. ... 0. 0. 0.]\n",
            "Augmented Dataset y[75] :  0.08333333333333333\n",
            "Average y_train :  0.5535714285714286\n",
            "Average y_train_augmented :  0.50625\n",
            "Epoch 1/10\n",
            "45/45 [==============================] - 1s 8ms/step - loss: 0.2071 - mean_absolute_error: 0.2071 - val_loss: 0.2597 - val_mean_absolute_error: 0.2597\n",
            "Epoch 2/10\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.2057 - mean_absolute_error: 0.2057 - val_loss: 0.2597 - val_mean_absolute_error: 0.2597\n",
            "Epoch 3/10\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.2043 - mean_absolute_error: 0.2043 - val_loss: 0.2597 - val_mean_absolute_error: 0.2597\n",
            "Epoch 4/10\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.2029 - mean_absolute_error: 0.2029 - val_loss: 0.2598 - val_mean_absolute_error: 0.2598\n",
            "Epoch 5/10\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.2016 - mean_absolute_error: 0.2016 - val_loss: 0.2598 - val_mean_absolute_error: 0.2598\n",
            "Epoch 6/10\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.2002 - mean_absolute_error: 0.2002 - val_loss: 0.2598 - val_mean_absolute_error: 0.2598\n",
            "Epoch 7/10\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.1990 - mean_absolute_error: 0.1990 - val_loss: 0.2598 - val_mean_absolute_error: 0.2598\n",
            "Epoch 8/10\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.1977 - mean_absolute_error: 0.1977 - val_loss: 0.2599 - val_mean_absolute_error: 0.2599\n",
            "Epoch 9/10\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.1964 - mean_absolute_error: 0.1964 - val_loss: 0.2599 - val_mean_absolute_error: 0.2599\n",
            "Epoch 10/10\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.1951 - mean_absolute_error: 0.1951 - val_loss: 0.2599 - val_mean_absolute_error: 0.2599\n",
            "For Augmented Model - \n",
            "Mean Absolute Error :  0.2951 Mean Squared Error :  0.1329\n",
            "*************************End of Part 1************\n",
            "Wrong Classification\n",
            "Sentence - no other codes nowdays seriously you cant build windmill without tons of concrete tons of steele roads cables deforestation shipping assembly just for an expected lifetime of years\n",
            "Predicted : 0.5141486 True 1.0\n",
            " \n",
            "Wrong Classification\n",
            "Sentence - doesn t green looks awesome rate of deforestation should not be more than rate of reforestation let s us cover our surrounding with urban dense forest either it s your kitchen or terrace trust me this green friend will keep you always happy\n",
            "Predicted : 0.5258515 True 1.0\n",
            " \n",
            "Wrong Classification\n",
            "Sentence - meet giselle is doing her phd on swift logging and sugar gliders her research is going to crack open knowledge of how deforestation affects the survival of swift parrots n\n",
            "Predicted : 0.4992511 True 1.0\n",
            " \n",
            "Wrong Classification\n",
            "Sentence - happy pangolins can be found in various habitats including tropical forests amp savannahs the eu must do its part to protect these habitats amp their biodiversity by proposing a strong eu deforestation law\n",
            "Predicted : 0.5550986 True 0.75\n",
            " \n",
            "Right Classification\n",
            "Sentence - impacto humano no human impact on\n",
            "Predicted : 0.4755459 True 0.5\n",
            " \n",
            "Right Classification\n",
            "Sentence - this could help for starters cane can also have a lot of secondary effects runoff into coral reefs deforestation child labour or be heavily subsidised would recommend reading threads if interested\n",
            "Predicted : 0.5392004 True 0.5\n",
            " \n",
            "Right Classification\n",
            "Sentence - madelaine y alfelor gazman mayor of iriga amp uclg treasurer emphasizes the potential of supporting local farmers to attain sustainable food security under the context of a circular economy which contributes to halting deforestation and supports communities\n",
            "Predicted : 0.48863375 True 0.5\n",
            " \n",
            "Right Classification\n",
            "Sentence - eu public opposes trade deal a recent survey shows public demands to stop prior to the deal in germany of respondents totally agree with the call to halt the agreement unless deforestation is stopped\n",
            "Predicted : 0.48290825 True 0.5\n",
            " \n",
            "Wrong Classification\n",
            "Sentence - deforestation will be the end of human race unless we put an end to deforestation\n",
            "Predicted : 0.53916 True 0.25\n",
            " \n",
            "Wrong Classification\n",
            "Sentence - i can t believe we are still allowing this deforestation and destruction of the amazon such beautiful wild rare animals and plants trees that can be used for medicine where are we headed un fking believable\n",
            "Predicted : 0.54083556 True 0.0\n",
            " \n",
            "Wrong Classification\n",
            "Sentence - what this all stupid things going on in our country i request our to take action against them who all are doing this stupid things we have to\n",
            "Predicted : 0.51867115 True 0.0\n",
            " \n",
            "Wrong Classification\n",
            "Sentence - not learning the age old lessons though are we unless you shut down factory farming and wet markets stop deforestation this list will keep on growing and how easy is it to swop a meal rather than endure lockdowns and deaths no brainer or it should be\n",
            "Predicted : 0.4446301 True 0.0\n",
            " \n",
            "Accuracy of Model :  0.33\n",
            "Got 4 out of 12 correct.\n",
            "X,y 0      three palm oil firms were responsible for a qu...\n",
            "1      despicable govt using as cover to dilute envir...\n",
            "2                      impacto humano no human impact on\n",
            "3      deforestation will be the end of the human rac...\n",
            "4      no other codes nowdays seriously you cant buil...\n",
            "                             ...                        \n",
            "934    sir david attenborough says we can protect wil...\n",
            "935    the silvery gibbon is of genus hylobates which...\n",
            "936                            how to stop deforestation\n",
            "937    do you accept the challenge before entering wh...\n",
            "938    the more lighter we take the subject of defore...\n",
            "Name: clean_text, Length: 939, dtype: object 0                          NaN\n",
            "1                          NaN\n",
            "2                  {'neutral'}\n",
            "3                          NaN\n",
            "4                 {'positive'}\n",
            "                ...           \n",
            "934                        NaN\n",
            "935                        NaN\n",
            "936    {'positive', 'neutral'}\n",
            "937                        NaN\n",
            "938               {'positive'}\n",
            "Name: sentiments_list, Length: 939, dtype: object\n",
            "len(y)-> 939\n",
            "impacto humano no human impact ...  1\n",
            "no other codes nowdays serious ...  1\n",
            "this could help for starters c ...  1\n",
            "doesn t green looks awesome ra ...  1\n",
            "madelaine y alfelor gazman may ...  1\n",
            "meet giselle is doing her phd  ...  1\n",
            "eu public opposes trade deal a ...  1\n",
            "fran ois lombard of underlined ...  1\n",
            "and partnered with communities ...  1\n",
            "and partnered with communities ...  1\n",
            "well said anna yes absolutely  ...  1\n",
            "deforestation will be the end  ...  0\n",
            "deforestation is changing our  ...  1\n",
            "to combat deforestation and he ...  1\n",
            "happy pangolins can be found i ...  1\n",
            "meateaters amp animal ag they  ...  1\n",
            "happy pangolins are facing ser ...  1\n",
            "is on world side so se support ...  1\n",
            "i can t believe we are still a ...  0\n",
            "envirolent day you are the sal ...  1\n",
            "what this all stupid things go ...  0\n",
            "that our beekeepers place beeh ...  1\n",
            "what an authentic vignette it  ...  0\n",
            "not learning the age old lesso ...  0\n",
            "soz but the two are incompatib ...  0\n",
            "in hundreds of years old pine  ...  1\n",
            "sorry sir no deforestation in  ...  1\n",
            "a kind reminder that deforesta ...  0\n",
            "to combat deforestation and he ...  1\n",
            "of people living in rural area ...  1\n",
            "program how can we actively re ...  1\n",
            "in artist klaus littmann turne ...  1\n",
            "i fail to understand our envir ...  1\n",
            "how to stop runaway deforestat ...  1\n",
            "how to stop runaway deforestat ...  1\n",
            "tropical are under increasing  ...  1\n",
            "according to tobacco is deadly ...  1\n",
            "this robot could help plant tr ...  1\n",
            "defines a restrictive policy t ...  1\n",
            "what is the evidence on crimin ...  1\n",
            "deforestation green recovery f ...  1\n",
            "an ambitious amp successful pl ...  1\n",
            "baka pygmies east cameroon the ...  1\n",
            "the black jaguar foundation pl ...  1\n",
            "the fta conflicts with ambitio ...  1\n",
            "forests cover of the earth s l ...  1\n",
            "this photo documents the exten ...  1\n",
            "bobble vytas and andreana swop ...  1\n",
            "your soy milk ain t the proble ...  1\n",
            "from to the to the us countrie ...  1\n",
            "deforestation ...  1\n",
            "urgent this is our call this i ...  1\n",
            "experts have made a sad observ ...  0\n",
            "did you know read more about s ...  1\n",
            "earthsight s grand theft chaco ...  1\n",
            "a bird view let it be green am ...  1\n",
            "treedom community hear us out  ...  1\n",
            "kudos to norway ...  1\n",
            "tackling is a complex issue an ...  1\n",
            "forests play a central role in ...  1\n",
            "deforestation of dahaiyagala s ...  1\n",
            "to celebrate our latest blog d ...  1\n",
            "human activity is driving almo ...  1\n",
            "great work from struan in s cr ...  1\n",
            "we can prevent by empowering a ...  1\n",
            "livestock livestock everywhere ...  0\n",
            "eco friendly black owned that  ...  1\n",
            "is on world side so se support ...  1\n",
            "calling on to list as a non pr ...  1\n",
            "meet the graduate students wor ...  1\n",
            "incoming call we are calling o ...  0\n",
            "the production of food has a m ...  1\n",
            "eu based banks are bankrolling ...  1\n",
            "class have been looking at def ...  1\n",
            "in our globalized distant conn ...  1\n",
            "but is cutting grown in appeal ...  1\n",
            "on march the will vote on a fr ...  1\n",
            "deforestation is one of the gr ...  1\n",
            "if the wants to lead the globa ...  1\n",
            "did you know before there were ...  1\n",
            "according to only basic produc ...  1\n",
            "this week s inspirational wome ...  1\n",
            "bnp paribas defines restrictiv ...  1\n",
            "with has launched a new partne ...  1\n",
            "threatens our prosperity and w ...  1\n",
            "is thriving in latin america o ...  1\n",
            "this sign reads it is prohibit ...  1\n",
            "forests play a key role in sus ...  1\n",
            "among the climate change fund  ...  1\n",
            "flegt compliance in ghana logg ...  1\n",
            "the brazilian cerrado is one o ...  1\n",
            "deforestation comparison below ...  1\n",
            "all our products are palm oil  ...  1\n",
            "key examples of human induced  ...  1\n",
            "it s today forests provide a c ...  1\n",
            "want to find out how deforesta ...  1\n",
            "soy used as animal feed for in ...  1\n",
            "today is let s remember the cr ...  1\n",
            "i know i should be prepping ta ...  1\n",
            "last year ferrero made signifi ...  1\n",
            "commodity driven deforestation ...  1\n",
            "civil society organizations ha ...  1\n",
            "p have been learning at home a ...  1\n",
            "and in forests are disappearin ...  1\n",
            "it s celebrating forests and t ...  1\n",
            "deforestation of the amazon an ...  1\n",
            "happy in it s celebrating how  ...  1\n",
            "unsustainable palm oil product ...  0\n",
            "you might think avoiding is th ...  1\n",
            "our forests are home to some c ...  1\n",
            "this seven year old girl is fi ...  1\n",
            "yes public the cult of meat ea ...  1\n",
            "in order to protect ourselves  ...  1\n",
            "did you know leopard spots are ...  1\n",
            "forests have a central role in ...  1\n",
            "wildlife is threatened by defo ...  1\n",
            "cameroon s forests are home to ...  1\n",
            "amazon indigenous groups sue c ...  1\n",
            "today brings to our attention  ...  1\n",
            "give back to nature is very ha ...  1\n",
            "happy forests play a central r ...  1\n",
            "is on world side so se support ...  1\n",
            "not only is organic it s also  ...  1\n",
            "when you notice it a movie abo ...  1\n",
            "year are learning about how th ...  1\n",
            "urban growth co solihull forge ...  1\n",
            "ag indicts for reckless drivin ...  0\n",
            "transparency is crucial in our ...  1\n",
            "that pallite products are made ...  1\n",
            "day of solutions live updates  ...  1\n",
            "the us relies heavily on impor ...  1\n",
            "unequal hours unraveling appro ...  1\n",
            "thank you for the article but  ...  1\n",
            "direct human causes of defores ...  1\n",
            "french supermarket chain sued  ...  1\n",
            "year have been celebrating by  ...  1\n",
            "climate change is cause by def ...  1\n",
            "could your shopping be contrib ...  0\n",
            "we ve reached the final day of ...  1\n",
            "event environmental justice in ...  1\n",
            "un suspends climate work with  ...  0\n",
            "gwg star of the week lesein mu ...  1\n",
            "we have a pretty extensive lis ...  1\n",
            "how is the covid pandemic conn ...  1\n",
            "governments of amp are priorit ...  1\n",
            "y all fuckin with deforestatio ...  1\n",
            "in an interview published on s ...  1\n",
            "week i tried to make a nice ye ...  1\n",
            "if a muslim who plants a tree  ...  0\n",
            "indigenous territories are vit ...  1\n",
            "indonesia and malaysia are now ...  1\n",
            "fertilizers play a key role in ...  1\n",
            "this report analyzes private i ...  1\n",
            "forest area skmc hospital camp ...  1\n",
            "another day another habitat de ...  1\n",
            "the forest has always been ass ...  1\n",
            "at least once a let s avoid ov ...  1\n",
            "award winning filmmaker and s  ...  1\n",
            "with the new feature called ti ...  1\n",
            "chile s varied landscapes are  ...  1\n",
            "nobdy understands by vry meani ...  0\n",
            "amp freshwater pollution have  ...  1\n",
            "is on world side so se support ...  1\n",
            "in as president of the duke of ...  1\n",
            "the transboundary region betwe ...  1\n",
            "no incidence of fire combined  ...  1\n",
            "our buy one get one tree promo ...  1\n",
            "soon do you want to learn abou ...  1\n",
            "boycott genshin mihoyo is not  ...  0\n",
            "chile s varied landscapes are  ...  1\n",
            "s menabe antimena protected ar ...  1\n",
            "global tree loss can t hide fr ...  1\n",
            "keep our planet green stop def ...  1\n",
            "calling all welsh schools size ...  1\n",
            "take majority land back livest ...  1\n",
            "happy birthday from montana de ...  1\n",
            "thank you alumni for creating  ...  1\n",
            "climate change is an risk that ...  1\n",
            "stanford study cause of the wa ...  1\n",
            "deforestation and corruption a ...  0\n",
            "the series o grito do brasil s ...  1\n",
            "plant trees and protect them t ...  1\n",
            "plant trees and protect them t ...  1\n",
            "plant trees and protect them t ...  1\n",
            "animation by will make you go  ...  0\n",
            "we have just signed up to to o ...  1\n",
            "investment giant holds million ...  1\n",
            "deforestation is threatening f ...  1\n",
            "voting with patriotism is fund ...  1\n",
            "don t forget to tune in instag ...  1\n",
            "when animals are safe from def ...  1\n",
            "co converters are already out  ...  1\n",
            "how to stop deforestation ...  1\n",
            "the more lighter we take the s ...  1\n",
            "   \n",
            "Collecting transformers\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.31.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6b99f55ae5b4cdd90252cbf7f562b57"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "450747f7572743dd8c55ee54499b10c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0fb6bc0b372b4f578d6f0b89a5aeeacd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d81b844fd8034217882269337e1b7d27"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_tokenized  {'input_ids': <tf.Tensor: shape=(155, 56), dtype=int32, numpy=\n",
            "array([[  101,  3113, 21025, ...,     0,     0,     0],\n",
            "       [  101,  2095,  2031, ...,     0,     0,     0],\n",
            "       [  101,  2025,  2069, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [  101,  2035,  2256, ...,     0,     0,     0],\n",
            "       [  101, 13366, 25794, ...,     0,     0,     0],\n",
            "       [  101,  1052,  2031, ...,     0,     0,     0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(155, 56), dtype=int32, numpy=\n",
            "array([[1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>}\n",
            "X_val_tokenized =  {'input_ids': <tf.Tensor: shape=(39, 54), dtype=int32, numpy=\n",
            "array([[  101,  2057,  2310, ...,     0,     0,     0],\n",
            "       [  101,  3407, 20657, ...,     0,     0,     0],\n",
            "       [  101,  1996,  3224, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [  101,  4372, 21663, ...,     0,     0,     0],\n",
            "       [  101, 17757,  8991, ...,   102,     0,     0],\n",
            "       [  101,  2465,  2031, ...,     0,     0,     0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(39, 54), dtype=int32, numpy=\n",
            "array([[1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 1, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>}\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " tf_distil_bert_for_sequence  TFSequenceClassifierOutp  66955010 \n",
            " _classification (TFDistilBe  ut(loss=None, logits=(No           \n",
            " rtForSequenceClassification  ne, 2),                            \n",
            " )                            hidden_states=None, att            \n",
            "                             entions=None)                       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 66,955,013\n",
            "Trainable params: 66,955,013\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "X_train_tokenized length :  2\n",
            "X_train_tokenized keys() :  dict_keys(['input_ids', 'attention_mask'])\n",
            "X_train_tokenized['input_ids'] length :  155\n",
            "X_train_tokenized['attention_mask'] length :  155\n",
            "X_train_tokenized['input_ids'][56] :  tf.Tensor(\n",
            "[  101  2529  4023  2003  4439  2471  2035  2174  2045  2024  4551  3224\n",
            " 12530  4630  2111  2023  2003  2028  3114  2339  2057  2024  4214  2005\n",
            "  2019  7327  2898  2895  2933  2000  9190 13366 25794  3191  2062  1999\n",
            "  2256  2597  3259   102     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0], shape=(56,), dtype=int32)\n",
            "X_train_tokenized['attention_mask'][56] :  tf.Tensor(\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(56,), dtype=int32)\n",
            "y_train length :  155\n",
            "4/4 [==============================] - 79s 14s/step - loss: 0.5087 - accuracy: 0.5806 - val_loss: 0.5641 - val_accuracy: 0.8710\n",
            "2/2 [==============================] - 7s 1s/step - loss: 0.4528 - accuracy: 0.8974\n",
            "Test loss: 0.45276403427124023\n",
            "Test accuracy: 0.8974359035491943\n",
            "Length of y_pred :  39\n",
            "Right Classification\n",
            "Sentence - [  101  2057  2310  2584  1996  2345  2154  1997  1998  2057  2128  4851\n",
            "  2054  2003  2045  1055  2023  1998  2062  2006  2256  4189  6494  3207\n",
            "  3481 15864  2489  4219  3931  2005  1998  5799  2917   102     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0]\n",
            "Predicted : 0.9861397 True 1\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101  3407 20657 18861  2015  2024  5307  3809  8767  2000  2037  4598\n",
            "  2027  2024 17800  4026  8126  2000  2789  4021  2349  2000  1996  6772\n",
            "  2008  2037  9539  9526  7870  2036  2037  6240  2003  3811  2359 13366\n",
            " 25794  2003  2178  5081 15536  3211 20330 18454 22272  2078   102     0\n",
            "     0     0     0     0     0     0]\n",
            "Predicted : 0.98629254 True 1\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101  1996  3224  2038  2467  2042  3378  2007  2273  2021  2057  2215\n",
            "  2000  2689  2008  2122  2308  7181  1999  6239  2024  2006  1037  3260\n",
            "  2000  2645 25883 13366 25794  1998  6870 13433 21046  3070   102     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0]\n",
            "Predicted : 0.98612165 True 1\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101 25176  2109  2004  4111  5438  2005  1999  2256  2833  4425  8859\n",
            "  2038  2419  2000 13366 25794 23713 17194  3279  1999  3182  2066  1996\n",
            "  9733  2057  2064  4047  6870  2011  4352  2256  3888  4176  2000 26918\n",
            "  2063  2006 20787  2030  8521  2068  2006  7246  4961 17588   102     0\n",
            "     0     0     0     0     0     0]\n",
            "Predicted : 0.98628557 True 1\n",
            " \n",
            "Right Classification\n",
            "Sentence - [ 101 4214 2006 2000 2862 2004 1037 2512 4031 5587 2115 2376 3696 3693\n",
            "  102    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            "Predicted : 0.9858636 True 1\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101  3224  2181 15315 12458  2902  3721  3531  2202  2019  6413  2895\n",
            "   102     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0]\n",
            "Predicted : 0.98595095 True 1\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101  1037  4743  3193  2292  2009  2022  2665 23713  4550  8811  1045\n",
            "  2514  2008 21358 29278  4355  3370  1999  1996  2171  1997 13366 25794\n",
            "  2011  6736  2003  1996  4928  1997 14427  2058  4348  3267  2009  1055\n",
            "  2051   102     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0]\n",
            "Predicted : 0.9862161 True 1\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101  6240  5243  7747 23713  4111 12943  2027  2074 10214  2000  2644\n",
            "  2000  4652  6090  3207 22924  1057  2031  2000  2203  3742  6240  5983\n",
            " 23713  1996  3378 13366 25794  6870  4288  3267  2003 12266  4176  2031\n",
            "  2116  7870  2000  3659  2000  2151 15267  2431  1037  4551  3888  4176\n",
            "  2031  2042 12731 11001  3728   102]\n",
            "Predicted : 0.9865512 True 1\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101  1999  2344  2000  4047  9731  2013  2925  6090  3207 22924  2057\n",
            "  2442  3305  1996  4957  2090  6552  3279  1998  7870  2066  2522 17258\n",
            "  2057  2442  2059  2655  2088  4177  2000  2202 13661  2895  2000  4652\n",
            "  2925  6090  3207 22924   102     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0]\n",
            "Predicted : 0.98616326 True 1\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101  2748  2270  1996  8754  1997  6240 28496  2015  7641  2866 14695\n",
            "  4142  2008  2015  4654  7913 26725  3426  1996  5409  4785  7071  5409\n",
            " 13366 25794  1996  2087  6677  1997  6870  2069  2187  2006  3426  2088\n",
            "  9012  2011  8521  8765  2000  4176  2025  2111  2738  1037  8754  2876\n",
            "  2102  2017  2360   102     0     0]\n",
            "Predicted : 0.9864731 True 1\n",
            " \n",
            "Wrong Classification\n",
            "Sentence - [  101  7284  2011  2097  2191  2017  2175  2013  2000  2428  2855  2396\n",
            " 10047 17570  2015  2166  2157  1996  2026  2069  2293  2011  4490  2004\n",
            "  1037 14764  1997  1996 22812 13366 25794  5320  2856  2011  9094  7439\n",
            "  2522  4013  2094  2011   102     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0]\n",
            "Predicted : 0.98629844 True 0\n",
            " \n",
            "Wrong Classification\n",
            "Sentence - [  101  1045  2064  1056  2903  2057  2024  2145  4352  2023 13366 25794\n",
            "  1998  6215  1997  1996  9733  2107  3376  3748  4678  4176  1998  4264\n",
            "  3628  2008  2064  2022  2109  2005  4200  2073  2024  2057  3753  4895\n",
            " 14352  2075 19337  2666 12423   102     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0]\n",
            "Predicted : 0.9862364 True 0\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101 24869  2361 11968 18410  2015 11859 25986  3343  2000  2954 13366\n",
            " 25794  1996  2924  2097  2069  3073  3361  3688  2030  2578  2000  3316\n",
            "  2007  1037  5656  2000  6162  5717 13366 25794  1999  2037  2537  1998\n",
            "  4425  8859  2011  2012  1996  6745   102     0     0     0     0     0\n",
            "     0     0     0     0     0     0]\n",
            "Predicted : 0.9862321 True 1\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101  1998 12404  2007  4279  8472  2213  1998  2697  9796  2000  6534\n",
            "  4264  2408  9076  2000  7901 13366 25794  6792  2062  2055  1996   102\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0]\n",
            "Predicted : 0.98589444 True 1\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101  1996  9099 15494  5649  2555  2090  2892  2314  2110 23713 25430\n",
            " 13841  2003  1037  7843  2980 13102  4140  2005 25662  8906  2021  5561\n",
            "  2011 13366 25794 23713  5933  2120  6328  2107  2004 27006 23093  2850\n",
            "  2892  2314 23713 12849 21531  5050  2037  2190  3382  2005  7691   102\n",
            "     0     0     0     0     0     0]\n",
            "Predicted : 0.986458 True 1\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101  9733  6284  2967  9790  9270  4677  2058 13366 25794   102     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0]\n",
            "Predicted : 0.98610234 True 1\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101  3113  1996  4619  2493  2551  1999  4380  6239  1998  7304  2040\n",
            "  2587 25022 29278  6529  2000 28866  2006  2019 12479  3795  5656  2000\n",
            "  5547 11768  2013 13366 25794 23713  3224 16627   102     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0]\n",
            "Predicted : 0.9859578 True 1\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101  2106  2017  2113 16240  7516  2024  2170  3123 14581  2138  2027\n",
            " 13014  1037  3123  2085  2017  2079  2023  2095  1055  2088  6870  2154\n",
            "  2003  2055  2129  4785  2689 23713 13366 25794  2024 15333 29477 17080\n",
            "  6774  3224  2427 23713  1996 24585  2015  1997  1996  2334  3224  4279\n",
            "   102     0     0     0     0     0]\n",
            "Predicted : 0.98648435 True 1\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101  2522 10463  2545  2024  2525  2041  1996  2155  2003  3652  2122\n",
            "  4606  3652  2013  4268  8019  1999  2023  2034  3049  2097  2599  2023\n",
            "  2621  2000  2062  2084  2005  3554 13366 25794  1998  4785  2689  2129\n",
            "  2009  2318  2129  2009  2003  2183   102     0     0     0     0     0\n",
            "     0     0     0     0     0     0]\n",
            "Predicted : 0.9863776 True 1\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101  2507  2067  2000  3267  2003  2200  3407  2000 14970  2037  5386\n",
            "  2007  8987  2813  2396  2027  2031  2525  8461  3628  1999  2752 25537\n",
            "  2011 13366 25794  1998  5462  2000 14685  3392  2005  2296 10683  2853\n",
            "   102     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0]\n",
            "Predicted : 0.9861386 True 1\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101  2043  2017  5060  2009  1037  3185  2055 13366 25794   102     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0]\n",
            "Predicted : 0.98584485 True 1\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101  6867  1997 23713  2024  3188 25090  6774  1996  4935  1997  1996\n",
            "  2943  4753  6502 25300  3070 23713 15899 23713  1996  2458  1997  3919\n",
            " 12943  2485  2000  2030  2503  6500 19927 29476  2075 15709  1997  2455\n",
            "  9775 23713  6206 13366 25794   102     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0]\n",
            "Predicted : 0.9861437 True 1\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101 17338  5379  2304  3079  2008  1055  1046  2497 13387  2015  2019\n",
            " 17338  5379  2194  2007  3688  2107  2004 15216 11848  3259 15216  7126\n",
            "  4652 10327  1998  4681  1999 10723 13366 25794  2022  2665 23713  2131\n",
            "  2125  2478  3642  2059  9463  9863  2031  2017  4497  5669  2304  2651\n",
            "   102     0     0     0     0     0]\n",
            "Predicted : 0.9865339 True 1\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101  6138  3104  1997  1996  3011  1055  2455  2664  1997  2455 11993\n",
            "  4264  2444  1999  2068 13718  2349  2000 13366 25794  6138  2071  2022\n",
            "  2908  2306  2086  2004  1037  4435  2431  1997  2256  6351  6495  2175\n",
            "  2000 13116  5680  3934  5094  2562  6138  4142   102     0     0     0\n",
            "     0     0     0     0     0     0]\n",
            "Predicted : 0.9862562 True 1\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101  2007  1996  2047  3444  2170  2051  2721 29251  2006  5198  2064\n",
            "  7409  2086  1997  2689  2408  1996  2972  8849  1996  2412  5278 10466\n",
            "  1997 15458  2015  3582  1996  3930  1997 13164 26243  3111  2650 13366\n",
            " 25794  1998  2172  2062   102     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0]\n",
            "Predicted : 0.9861616 True 1\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101  6870  2003  5561  2011 13366 25794  2605  2003  5462  2007  1996\n",
            "  4707  2005  1996  8347  1997  5133  6138  3390  1999  2000 13530  2248\n",
            "  2895  2000  4047  2122  6138  1998  2037  2427   102     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0]\n",
            "Predicted : 0.9860194 True 1\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101  2003  2006  2088  2217  2061  7367  2490  2114 13366 25794  1997\n",
            "  2017  2064 21357  2182   102     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0]\n",
            "Predicted : 0.98591995 True 1\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101  3145  4973  1997  2529 10572  6552  3279  2421 13366 25794  4910\n",
            "  4935  1998  3923  3989   102     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0]\n",
            "Predicted : 0.98616725 True 1\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101  2565  2129  2064  2057  8851 19444  1996  2954  2114  1999  2129\n",
            "  2064  2057  1999  1037  2126  9851  8040 18663  2497  8777  2094  2011\n",
            "  2233   102     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0]\n",
            "Predicted : 0.98592806 True 1\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101  2942  2554  4411  2031  2517  2019  2330  3661  2000  3519  1998\n",
            "  1996  7226  2368  5671  3447  2000 16599  2895  2006 26997  2989  3795\n",
            " 13366 25794  3191  2009  2182   102     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0]\n",
            "Predicted : 0.9860203 True 1\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101  2651  7545  2000  2256  3086  2074  2129  6970 13767  2098  2024\n",
            " 17194  3279  4785  2689  1998 13366 25794  2024 23807  3973  5799  2057\n",
            "  2442  4337  1996  8767  2000  2256 20440  2061  2057  2123  1056  2203\n",
            "  2039  2007  1037   102     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0]\n",
            "Predicted : 0.9861968 True 1\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101  2021  2003  6276  4961  1999 16004  2000  3242  2000 20228  2015\n",
            "  2644  3742 13366 25794  6886  6534 18510  2180  1056  2079  2204  2065\n",
            "  2017  2292  3613  2000  3013  2214  3628  2035  2005   102     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0]\n",
            "Predicted : 0.9861008 True 1\n",
            " \n",
            "Wrong Classification\n",
            "Sentence - [  101  2061  2480  2021  1996  2048  2024 25876  4111  5237  1996  2053\n",
            "  3426  1997 13366 25794  1998  6552  4487  3367  6820  7542  5221 12130\n",
            "  2000  3795 12959  2128  2102 28394  2078  2065  2017  2128  1059  2033\n",
            "   102     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0]\n",
            "Predicted : 0.9862331 True 0\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101  2562  2256  4774  2665  2644 13366 25794  1998 27749  2943   102\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0]\n",
            "Predicted : 0.9861061 True 1\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101 16987  2003 10232  1999  2256  2954  2114 13366 25794  1998  3224\n",
            " 16627  2047  3027  2050  2551  3259 15252 11107  2000  5326  9084  4425\n",
            "  8859  1996  2553  1997  3224  3891 21955   102     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0]\n",
            "Predicted : 0.9860175 True 1\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101  7029  1055  9426 12793  2024  2108 19209  2011  8769  1998  2003\n",
            "  4804  1037  2047  2419  2622  2008  2097  4047 20440  1998  2427  2073\n",
            "  2027  2024  2087  2012  3891   102     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0]\n",
            "Predicted : 0.98598534 True 1\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101  4372 21663  9890  3372  2154  2017  2024  1996  5474  1997  1996\n",
            "  3011  2017  2024  1996  2422  1997  1996  2088  5487  4119  2175  2005\n",
            "  1037  3328  2030  1037  2448  1999 14657  2007 16836  1998  8711  2040\n",
            "  2031  2018  2000 10574  2037 10759  2138  1997  4803  2300 13366 25794\n",
            "  1998  2162   102     0     0     0]\n",
            "Predicted : 0.98651516 True 1\n",
            " \n",
            "Wrong Classification\n",
            "Sentence - [  101 17757  8991 17426  2771  6806  7677  2003  2025 14622  1996 29172\n",
            " 13531  1997  3795 12959  1998  4785  2689  2011  5815 13366 25794  2004\n",
            "  1037  9095  2005  1996  2447  3847  2291  2036  2115  5448  3475  1056\n",
            "  2734  2004  2017  4995  1056  1037  7162  2358 11263  1998  2079  2054\n",
            "  1045  2360  1039   102     0     0]\n",
            "Predicted : 0.9865478 True 0\n",
            " \n",
            "Right Classification\n",
            "Sentence - [  101  2465  2031  2042  2559  2012 13366 25794  1998  1996  2005  1998\n",
            "  2114  9918  2298  2012  2023  2092 12042 21386  1043 18418  2818  2129\n",
            "  2079  2017  2514  2055 13366 25794   102     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0]\n",
            "Predicted : 0.98604566 True 1\n",
            " \n",
            "Accuracy of Model :  0.9\n",
            "Got 35 out of 39 correct.\n"
          ]
        }
      ],
      "source": [
        "#Point No. 1\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from cleantext import clean\n",
        "import numpy as np\n",
        "\n",
        "#Point No. 2\n",
        "data = pd.read_csv('/content/drive/My Drive/deforestation_sentiment_train.csv')\n",
        "print(\"1.  Details after data loading\")\n",
        "#print(data.describe)\n",
        "print(data.columns)\n",
        "print(data.head(5))\n",
        "print(data.tail(5))\n",
        "\n",
        "#Point No. 3\n",
        "#def clean_text(sentence):\n",
        "#Removes all special characters from sentence. It will also strip out\n",
        "# extra whitespace and makes the string lowercase.\n",
        "#  clean(sentence, no_emoji=True)\n",
        "#  return re.sub(r'[\\\\\\\\/:*«`\\'?¿\";!<>,.|]', '', sentence.lower().strip())\n",
        "\n",
        "def clean_text(sentence):\n",
        "    # Remove URLs\n",
        "     sentence = re.sub(r'http\\S+', '', sentence)\n",
        "    # Remove hashtags and mentions\n",
        "     sentence = re.sub(r'#\\w+|\\@\\w+', '', sentence)\n",
        "    # Remove special characters and numbers\n",
        "     sentence = re.sub(r'[^a-zA-Z]', ' ', sentence)\n",
        "    # Convert to lowercase\n",
        "     sentence = sentence.lower()\n",
        "    # Remove extra spaces\n",
        "     sentence = re.sub(r'\\s+', ' ', sentence).strip()\n",
        "    # Remove emojis\n",
        "#   clean(sentence, no_emoji=True)\n",
        "     return sentence\n",
        "\n",
        "#data[\"clean_text\"] = data[\"text\"]\n",
        "data['clean_text'] = data['text'].apply(clean_text)\n",
        "print(\"2. Clean Text -----------\")\n",
        "print(data['clean_text'])\n",
        "print(data.columns)\n",
        "print(data.head(5))\n",
        "#Point # 4\n",
        "X = data[\"clean_text\"]\n",
        "y = data[\"sentiments_list\"]  # sentiment label\n",
        "# y = ['', \"{'negative'}\", \"{'neutral', 'negative'}\" .. ]\n",
        "print(\"X,y\",X, y)\n",
        "X_updated = []\n",
        "y_updated = []\n",
        "print(\"len(y)->\",len(y))\n",
        "for sentiment_list_ind in range(0, len(y)):\n",
        "    #print(str(y[sentiment_list_ind]))\n",
        "    if (str(y[sentiment_list_ind]) == 'nan'):\n",
        "        continue\n",
        "    else:\n",
        "        # print(y[sentiment_list_ind])\n",
        "        current_sentiment_list = eval('[' + y[sentiment_list_ind][1 : -1] + ']')\n",
        "        neg_count = 0\n",
        "        neutral_count = 0\n",
        "        pos_count = 0\n",
        "        #print(\"current_sentiment_list\", current_sentiment_list)\n",
        "        for sentiment in current_sentiment_list:\n",
        "            if (sentiment == 'positive'):\n",
        "                pos_count += 1\n",
        "            if (sentiment == 'negative'):\n",
        "                neg_count += 1\n",
        "            if (sentiment == 'neutral'):\n",
        "                neutral_count += 1\n",
        "        # neg = 2, neutral = 3, pos = 4\n",
        "        score = (neg_count * 0 + neutral_count * 0.5 + pos_count * 1.0)/(neg_count + neutral_count + pos_count)\n",
        "\n",
        "        y_updated.append(score)\n",
        "        X_updated.append(X[sentiment_list_ind])\n",
        "\n",
        "for i in range(0, len(X_updated)):\n",
        "    print(X_updated[i][:30] + \" ... \", y_updated[i])\n",
        "print(\"   \")\n",
        "\n",
        "# Point No. 5\n",
        "\n",
        "# labels = set(y)\n",
        "\n",
        "# Split all our sentences\n",
        "elements = (' '.join([sentence for sentence in X_updated])).split()\n",
        "elements.append(\"<UNK>\")\n",
        "print(len(elements))\n",
        "print(len(np.unique(elements)))\n",
        "print(elements[:20])\n",
        "\n",
        "\n",
        "\n",
        "#Training a Recurrent Neural Network:\n",
        "#   Collect a vocabulary of words\n",
        "#   Generate look-up tables, word-to-int and int-to-word\n",
        "#   Represent my data as integers not strings\n",
        "#   One-hot encode them\n",
        "\n",
        "def create_lookup_tables(text):\n",
        "#Create lookup tables for vocabulary  :param text: The text split into words\n",
        "#return: A tuple of dicts (vocab_to_int, int_to_vocab)\n",
        "    vocab = set(text)\n",
        "\n",
        "    vocab_to_int = {word: i for i, word in enumerate(vocab)}\n",
        "    int_to_vocab = {v:k for k, v in vocab_to_int.items()}\n",
        "\n",
        "    return vocab_to_int, int_to_vocab\n",
        "\n",
        "\n",
        "#it creates two look-up tables…\n",
        "vocab_to_int, int_to_vocab = create_lookup_tables(elements)\n",
        "#print(\"vocab_to_int\", vocab_to_int)\n",
        "#print(\"int_to_vocab\", int_to_vocab)\n",
        "print(\"***************vocab_to_int.keys, vocab_to_int.values ********\")\n",
        "print(list(vocab_to_int.keys())[:5], list(vocab_to_int.values())[:5])\n",
        "print(\"***************int_to_vocab.keys, int_to_vocab.values ********\")\n",
        "print(list(int_to_vocab.keys())[:5], list(int_to_vocab.values())[:5])\n",
        "#languages_to_int, int_to_languages = create_lookup_tables(y)\n",
        "\n",
        "#size of our vocabulary.\n",
        "print(\"Vocabulary of our dataset: {}\".format(len(vocab_to_int)))\n",
        "\n",
        "#Point No. 6\n",
        "#Now is also a good time to split our data into a train and test set.\n",
        "#\n",
        "# Python’s sklearn package provides us with functionality to do this, using the\n",
        "#code below. Note that X_train will be the training data (i.e. review texts) used during the training\n",
        "#phase, while y_train will be the labels (positive, negative, neutral) used during training. X_test and y_test\n",
        "#are held out at this stage so we can use them for evaluation later on.\n",
        "\n",
        "pos_count = 0\n",
        "pos_indices = []\n",
        "neu_count = 0\n",
        "neu_indices = []\n",
        "neg_count = 0\n",
        "neg_indices = []\n",
        "for i in range(0, len(y_updated)):\n",
        "    if (y_updated[i] > 0.6667):\n",
        "        pos_count += 1\n",
        "        pos_indices.append(i)\n",
        "    elif (y_updated[i] > 0.3334):\n",
        "        neu_count += 1\n",
        "        neu_indices.append(i)\n",
        "    else:\n",
        "        neg_count += 1\n",
        "        neg_indices.append(i)\n",
        "print(\"Data stats - \")\n",
        "print(pos_count, neu_count, neg_count)\n",
        "\n",
        "X_test = []\n",
        "y_test = []\n",
        "for category in [pos_indices, neu_indices, neg_indices]:\n",
        "    for i in range(0, 4):\n",
        "        X_test.append(X_updated[category[i]])\n",
        "        y_test.append(y_updated[category[i]])\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "X_train = []\n",
        "y_train = []\n",
        "for category in [pos_indices, neu_indices, neg_indices]:\n",
        "    for i in range(4, len(category)):\n",
        "        X_train.append(X_updated[category[i]])\n",
        "        y_train.append(y_updated[category[i]])\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "print(\"Feature Shapes:\")\n",
        "print(\"\\tTrain set: \\t\\t{}\".format(X_train.shape), \"\\n\\tTest set: \\t\\t{}\".format(X_test.shape))\n",
        "print(\"Totals:\\n\\tWords in our Dataset: {}\\n\".format(len(np.unique(elements))))\n",
        "\n",
        "#3. Represent data numerically…\n",
        "\n",
        "def convert_to_int(data, data_int):\n",
        "    #Converts all our text to integers :param data: The text to be converted\n",
        "    #:return: All sentences in ints\n",
        "    all_items = []\n",
        "    for sentence in data:\n",
        "        all_items.append([data_int[word] if word in data_int else data_int[\"<UNK>\"] for word in sentence.split()])\n",
        "    return all_items\n",
        "\n",
        "\n",
        "# Convert our inputs\n",
        "X_test_encoded = convert_to_int(X_test, vocab_to_int)\n",
        "X_train_encoded = convert_to_int(X_train, vocab_to_int)\n",
        "\n",
        "print(X_train_encoded)\n",
        "print(X_test_encoded)\n",
        "\n",
        "#\n",
        "print(y_train)\n",
        "print(y_test)\n",
        "\n",
        "def generate_encoding(sample, vocab_to_int):\n",
        "    sorted_words = np.array(list(vocab_to_int.keys()))\n",
        "    embedding = np.zeros(len(sorted_words))\n",
        "    for word_ind in sample:\n",
        "            embedding[word_ind] += 1\n",
        "    return embedding\n",
        "\n",
        "\n",
        "X_train_encoded_embedding = []\n",
        "print(len(X_train_encoded))\n",
        "for encoded_val in X_train_encoded:\n",
        "        X_train_encoded_embedding.append(generate_encoding(encoded_val, vocab_to_int))\n",
        "X_train_encoded_embedding = np.array(X_train_encoded_embedding)\n",
        "print(X_train_encoded_embedding.shape)\n",
        "y_train = np.array(y_train)\n",
        "print(y_train.shape)\n",
        "\n",
        "X_test_encoded_embedding = []\n",
        "print(len(X_test_encoded))\n",
        "for encoded_val in X_test_encoded:\n",
        "        X_test_encoded_embedding.append(generate_encoding(encoded_val, vocab_to_int))\n",
        "X_test_encoded_embedding = np.array(X_test_encoded_embedding)\n",
        "print(X_test_encoded_embedding.shape)\n",
        "y_test = np.array(y_test)\n",
        "print(y_test.shape)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "#Point No 7\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the layers\n",
        "model.add(Dense(128, activation='relu', input_shape=(1768,)))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.SGD(\n",
        "    learning_rate=1e-4\n",
        "    )\n",
        "model.compile(optimizer=optimizer, loss='mean_absolute_error', metrics=['mean_absolute_error'])\n",
        "\n",
        "# Print the model summary\n",
        "print(model.summary())\n",
        "\n",
        "#\n",
        "\n",
        "# stats\n",
        "pos_count = 0\n",
        "pos_indices = []\n",
        "neu_count = 0\n",
        "neu_indices = []\n",
        "neg_count = 0\n",
        "neg_indices = []\n",
        "for i in range(0, len(y_train)):\n",
        "    if (y_train[i] > 0.6667):\n",
        "        pos_count += 1\n",
        "        pos_indices.append(i)\n",
        "    elif (y_train[i] > 0.3334):\n",
        "        neu_count += 1\n",
        "        neu_indices.append(i)\n",
        "    else:\n",
        "        neg_count += 1\n",
        "        neg_indices.append(i)\n",
        "print(pos_count, neu_count, neg_count)\n",
        "# prints (35, 106, 14)\n",
        "# creating validation set with 4 from each\n",
        "X_val_encoded_embedding = []\n",
        "y_val = []\n",
        "for category in [pos_indices, neu_indices, neg_indices]:\n",
        "    for i in range(0, 4):\n",
        "        X_val_encoded_embedding.append(X_train_encoded_embedding[category[i]])\n",
        "        y_val.append(y_train[category[i]])\n",
        "X_val_encoded_embedding = np.array(X_val_encoded_embedding)\n",
        "y_val = np.array(y_val)\n",
        "# augmenting dataset\n",
        "# X_train_encoded_embedding, y_train\n",
        "import random\n",
        "\n",
        "X_train_encoded_embedding_augmented = []\n",
        "y_train_augmented = []\n",
        "\n",
        "for category in [pos_indices[4 : ], neu_indices[4 : ], neg_indices[4 : ]]:\n",
        "    for i in range(30):\n",
        "        number_of_tweets_to_append = random.randint(0, 3) + 1\n",
        "        indices_of_tweets_to_append = []\n",
        "        for j in range(0, number_of_tweets_to_append):\n",
        "            indices_of_tweets_to_append.append(category[random.randint(1, len(category) - 1)])\n",
        "        augmented_score = 0\n",
        "        for j in range(0, number_of_tweets_to_append):\n",
        "            augmented_score += y_train[indices_of_tweets_to_append[j]]\n",
        "        augmented_score = augmented_score * 1.0/number_of_tweets_to_append\n",
        "        augmented_sample = np.zeros(1768)\n",
        "        for j in range(0, number_of_tweets_to_append):\n",
        "            augmented_sample = augmented_sample + X_train_encoded_embedding[indices_of_tweets_to_append[j]]\n",
        "        # print(number_of_tweets_to_append, indices_of_tweets_to_append, augmented_score)\n",
        "        X_train_encoded_embedding_augmented.append(augmented_sample)\n",
        "        y_train_augmented.append(augmented_score)\n",
        "\n",
        "X_train_encoded_embedding_augmented = np.array(X_train_encoded_embedding_augmented)\n",
        "y_train_augmented = np.array(y_train_augmented)\n",
        "\n",
        "print(\"Augmented Dataset X : \", X_train_encoded_embedding_augmented.shape)\n",
        "print(\"Augmented Dataset y : \", y_train_augmented.shape)\n",
        "print(\"Augmented Dataset X[75] : \", X_train_encoded_embedding_augmented[75])\n",
        "print(\"Augmented Dataset y[75] : \", y_train_augmented[75])\n",
        "\n",
        "print(\"Average y_train : \", np.mean(y_train))\n",
        "print(\"Average y_train_augmented : \", np.mean(y_train_augmented))\n",
        "\n",
        "train_history_augmented = model.fit(X_train_encoded_embedding_augmented, y_train_augmented, epochs=10, batch_size=2, validation_data = (X_val_encoded_embedding, y_val)\n",
        "          , verbose = 1\n",
        "        )\n",
        "\n",
        "y_pred = model.predict(X_test_encoded_embedding, verbose = 0)\n",
        "\n",
        "test_mae = 0\n",
        "test_mse = 0\n",
        "# mean absolute error, mean squared error, crossentropy (?)\n",
        "\n",
        "for i in range(0, len(y_pred)):\n",
        "    ae = abs(y_pred[i] - y_test[i])\n",
        "    se = ae * ae\n",
        "    test_mae += ae\n",
        "    test_mse += se\n",
        "test_mae = test_mae/len(y_pred)\n",
        "test_mse = test_mse/len(y_pred)\n",
        "print(\"For Augmented Model - \")\n",
        "print(\"Mean Absolute Error : \", round(test_mae[0], 4), \"Mean Squared Error : \", round(test_mse[0], 4))\n",
        "print(\"*************************End of Part 1************\")\n",
        "# 0 -> negative, 0.25 -> neutral negative, 0.5 -> neutral, 0.75 -> neutral_positive, 1 -> positive\n",
        "\n",
        "count_right_pred = 0\n",
        "for i in range(0, len(y_pred)):\n",
        "    # positive, neutral, negative\n",
        "    if (y_pred[i] > 0.6667):\n",
        "        pred_sentiment = 1.0\n",
        "    elif (y_pred[i] > 0.3334):\n",
        "        pred_sentiment = 0.5\n",
        "    else:\n",
        "        pred_sentiment = 0.0\n",
        "    if (y_test[i] > 0.6667):\n",
        "        true_sentiment = 1.0\n",
        "    elif (y_test[i] > 0.3334):\n",
        "        true_sentiment = 0.5\n",
        "    else:\n",
        "        true_sentiment = 0.0\n",
        "    if (pred_sentiment == true_sentiment):\n",
        "        print(\"Right Classification\")\n",
        "        print(\"Sentence -\", X_test[i])\n",
        "        print(\"Predicted :\", y_pred[i][0], \"True\", y_test[i])\n",
        "        print(\" \")\n",
        "        count_right_pred += 1\n",
        "    else:\n",
        "        print(\"Wrong Classification\")\n",
        "        print(\"Sentence -\", X_test[i])\n",
        "        print(\"Predicted :\", y_pred[i][0], \"True\", y_test[i])\n",
        "        print(\" \")\n",
        "print(\"Accuracy of Model : \", round(count_right_pred/len(y_pred), 2))\n",
        "print(\"Got\", count_right_pred, \"out of\", len(y_test), \"correct.\")\n",
        "\n",
        "\n",
        "#######################Part2 - DistilBirt for sentiment analysis##########################\n",
        "#Point No. 1\n",
        "'''import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from cleantext import clean\n",
        "import numpy as np\n",
        "\n",
        "#Point No. 2\n",
        "data = pd.read_csv('deforestation_sentiment_train.csv')\n",
        "print(\"1.  Details after data loading\")\n",
        "#print(data.describe)\n",
        "print(data.columns)\n",
        "print(data.head(5))\n",
        "print(data.tail(5))\n",
        "\n",
        "#Point No. 3\n",
        "\n",
        "#def clean_text(sentence):\n",
        "#Removes all special characters from sentence. It will also strip out\n",
        "# extra whitespace and makes the string lowercase.\n",
        "#  clean(sentence, no_emoji=True)\n",
        "#  return re.sub(r'[\\\\\\\\/:*«`\\'?¿\";!<>,.|]', '', sentence.lower().strip())\n",
        "\n",
        "\n",
        "\n",
        "def clean_text(sentence):\n",
        "    # Removes all special characters from sentence.\n",
        "    # It will also strip out extra whitespace and makes the string lowercase.\n",
        "\n",
        "    # Remove URLs\n",
        "    sentence = re.sub(r'http\\S+', '', sentence)\n",
        "    # Remove hashtags and mentions\n",
        "    sentence = re.sub(r'#\\w+|\\@\\w+', '', sentence)\n",
        "    # Remove special characters and numbers\n",
        "    sentence = re.sub(r'[^a-zA-Z]', ' ', sentence)\n",
        "    # Convert to lowercase\n",
        "    sentence = sentence.lower()\n",
        "    # Remove extra spaces\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence).strip()\n",
        "    # Remove emojis\n",
        "    clean(sentence, no_emoji=True)\n",
        "    return sentence\n",
        "\n",
        "data['clean_text'] = data['text'].apply(clean_text)\n",
        "print(\"2. Clean Text -----------\")\n",
        "print(data['clean_text'])\n",
        "print(data.columns)\n",
        "print(data.head(5))'''\n",
        "#Point # 4\n",
        "X = data[\"clean_text\"]\n",
        "y = data[\"sentiments_list\"]  # sentiment label\n",
        "# y = ['', \"{'negative'}\", \"{'neutral', 'negative'}\" .. ]\n",
        "print(\"X,y\",X, y)\n",
        "X_updated = []\n",
        "y_updated = []\n",
        "print(\"len(y)->\",len(y))\n",
        "for sentiment_list_ind in range(0, len(y)):\n",
        "    if (str(y[sentiment_list_ind]) == 'nan'):\n",
        "        continue\n",
        "    else:\n",
        "        current_sentiment_list = eval('[' + y[sentiment_list_ind][1 : -1] + ']')\n",
        "        neg_count = 0\n",
        "        neutral_count = 0\n",
        "        pos_count = 0\n",
        "        score = 1\n",
        "        #print(\"current_sentiment_list\", current_sentiment_list)\n",
        "        for sentiment in current_sentiment_list:\n",
        "            if (sentiment == 'positive'):\n",
        "                score = 1\n",
        "            if (sentiment == 'negative'):\n",
        "                score = 0\n",
        "        y_updated.append(score)\n",
        "        X_updated.append(X[sentiment_list_ind])\n",
        "\n",
        "for i in range(0, len(X_updated)):\n",
        "    print(X_updated[i][:30] + \" ... \", y_updated[i])\n",
        "print(\"   \")\n",
        "# input(\"Press any key to continue...\")\n",
        "#Now is also a good time to split our data into a train and test set.\n",
        "\n",
        "import tensorflow as tf\n",
        "!pip install transformers\n",
        "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "# Assuming you have your input data in 'X_train' and corresponding labels in 'y_train'\n",
        "# Split the data into train and validation sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_updated, y_updated, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load the DistilBERT tokenizer and model\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "distilbert_model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Tokenize the text data and convert to input tensors\n",
        "\n",
        "def tokenize_texts(texts):\n",
        "    return tokenizer(texts, padding=True, truncation=True, return_tensors='tf')\n",
        "\n",
        "X_train_tokenized = tokenize_texts(X_train)\n",
        "X_test_tokenized = tokenize_texts(X_test)\n",
        "\n",
        "print(\"X_train_tokenized \", X_train_tokenized)\n",
        "print(\"X_val_tokenized = \", X_test_tokenized)\n",
        "# Create the Keras model\n",
        "model = Sequential()\n",
        "model.add(tf.keras.layers.Input(shape=(None,), dtype='int32'))\n",
        "model.add(distilbert_model)\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "print(model.summary())\n",
        "# input(\"Model Summary\")\n",
        "print(\"X_train_tokenized length : \", len(X_train_tokenized))\n",
        "print(\"X_train_tokenized keys() : \", X_train_tokenized.keys())\n",
        "print(\"X_train_tokenized['input_ids'] length : \", len(X_train_tokenized['input_ids']))\n",
        "print(\"X_train_tokenized['attention_mask'] length : \", len(X_train_tokenized['attention_mask']))\n",
        "print(\"X_train_tokenized['input_ids'][56] : \", X_train_tokenized['input_ids'][56])\n",
        "print(\"X_train_tokenized['attention_mask'][56] : \", X_train_tokenized['attention_mask'][56])\n",
        "print(\"y_train length : \", len(y_train))\n",
        "# Train the model with your data (X_train_tokenized and y_train)\n",
        "model.fit(np.array(X_train_tokenized['input_ids']), np.array(y_train), epochs=1, batch_size=32, validation_split = 0.2, verbose = 1)\n",
        "\n",
        "# Evaluate the model on the test set if available\n",
        "# Assuming you have test data in 'X_test' and corresponding labels in 'y_test'\n",
        "loss, accuracy = model.evaluate(np.array(X_test_tokenized['input_ids']), np.array(y_test))\n",
        "print(\"Test loss:\", loss)\n",
        "print(\"Test accuracy:\", accuracy)\n",
        "\n",
        "y_pred = model.predict(np.array(X_test_tokenized['input_ids']), verbose = 0)\n",
        "y_test = np.array(y_test)\n",
        "X_test = np.array(X_test_tokenized['input_ids'])\n",
        "print(\"Length of y_pred : \", len(y_pred))\n",
        "count_right_pred = 0\n",
        "for i in range(0, len(y_pred)):\n",
        "    # negative, neutral, positive\n",
        "    if (y_pred[i] > 0.5):\n",
        "        pred_sentiment = 1.0\n",
        "    else:\n",
        "        pred_sentiment = 0.0\n",
        "    if (y_test[i] > 0.5):\n",
        "        true_sentiment = 1.0\n",
        "    else:\n",
        "        true_sentiment = 0.0\n",
        "    if (pred_sentiment == true_sentiment):\n",
        "        print(\"Right Classification\")\n",
        "        print(\"Sentence -\", X_test[i])\n",
        "        print(\"Predicted :\", y_pred[i][0], \"True\", y_test[i])\n",
        "        print(\" \")\n",
        "        count_right_pred += 1\n",
        "    else:\n",
        "        print(\"Wrong Classification\")\n",
        "        print(\"Sentence -\", X_test[i])\n",
        "        print(\"Predicted :\", y_pred[i][0], \"True\", y_test[i])\n",
        "        print(\" \")\n",
        "print(\"Accuracy of Model : \", round(count_right_pred/len(y_pred), 2))\n",
        "print(\"Got\", count_right_pred, \"out of\", len(y_test), \"correct.\")\n"
      ]
    }
  ]
}